test -s /home/ubuntu/go/src/kuberay/ray-operator/bin/controller-gen || GOBIN=/home/ubuntu/go/src/kuberay/ray-operator/bin go install sigs.k8s.io/controller-tools/cmd/controller-gen@v0.13.0
/home/ubuntu/go/src/kuberay/ray-operator/bin/controller-gen "crd:maxDescLen=0,generateEmbeddedObjectMeta=true,allowDangerousTypes=true" rbac:roleName=kuberay-operator webhook paths="./..." output:crd:artifacts:config=config/crd/bases
/home/ubuntu/go/src/kuberay/ray-operator/bin/controller-gen object:headerFile="hack/boilerplate.go.txt" paths="./..."
go fmt ./...
go vet ./...
test -s /home/ubuntu/go/src/kuberay/ray-operator/bin/setup-envtest || GOBIN=/home/ubuntu/go/src/kuberay/ray-operator/bin go install sigs.k8s.io/controller-runtime/tools/setup-envtest@latest
KUBEBUILDER_ASSETS="/home/ubuntu/go/src/kuberay/ray-operator/bin/k8s/1.24.2-linux-amd64" go test github.com/ray-project/kuberay/ray-operator github.com/ray-project/kuberay/ray-operator/apis/ray/v1 github.com/ray-project/kuberay/ray-operator/apis/ray/v1alpha1 github.com/ray-project/kuberay/ray-operator/controllers/ray github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler/interface github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler/volcano github.com/ray-project/kuberay/ray-operator/controllers/ray/common github.com/ray-project/kuberay/ray-operator/controllers/ray/utils github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/fake github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/scheme github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/typed/ray/v1 github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/typed/ray/v1/fake github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/internalinterfaces github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/ray github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/ray/v1 github.com/ray-project/kuberay/ray-operator/pkg/client/listers/ray/v1 -coverprofile cover.out -test.v
?   	github.com/ray-project/kuberay/ray-operator	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler/interface	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/fake	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/scheme	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/typed/ray/v1	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/typed/ray/v1/fake	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/internalinterfaces	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/ray	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/ray/v1	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/listers/ray/v1	[no test files]
=== RUN   TestMarshalling
--- PASS: TestMarshalling (0.01s)
=== RUN   TestMarshallingRayJob
--- PASS: TestMarshallingRayJob (0.00s)
=== RUN   TestMarshallingRayService
--- PASS: TestMarshallingRayService (0.00s)
=== RUN   TestAPIs
Running Suite: Webhook Suite - /home/ubuntu/go/src/kuberay/ray-operator/apis/ray/v1
===================================================================================
Random Seed: [1m1702058539[0m

Will run [1m1[0m of [1m1[0m specs
[38;5;10mâ€¢[0m

[38;5;10m[1mRan 1 of 1 Specs in 13.779 seconds[0m
[38;5;10m[1mSUCCESS![0m -- [38;5;10m[1m1 Passed[0m | [38;5;9m[1m0 Failed[0m | [38;5;11m[1m0 Pending[0m | [38;5;14m[1m0 Skipped[0m
--- PASS: TestAPIs (13.78s)
PASS
coverage: 9.5% of statements
ok  	github.com/ray-project/kuberay/ray-operator/apis/ray/v1	13.882s	coverage: 9.5% of statements
=== RUN   TestMarshalling
--- PASS: TestMarshalling (0.00s)
=== RUN   TestMarshallingRayJob
--- PASS: TestMarshallingRayJob (0.00s)
=== RUN   TestMarshallingRayService
--- PASS: TestMarshallingRayService (0.00s)
PASS
coverage: 0.7% of statements
ok  	github.com/ray-project/kuberay/ray-operator/apis/ray/v1alpha1	0.053s	coverage: 0.7% of statements
=== RUN   TestAPIs
Running Suite: Controller Suite - /home/ubuntu/go/src/kuberay/ray-operator/controllers/ray
==========================================================================================
Random Seed: [1m1702058540[0m

Will run [1m13[0m of [1m13[0m specs
2023-12-08T18:02:20Z	DEBUG	controller-runtime.test-env	starting control plane
2023-12-08T18:02:28Z	DEBUG	controller-runtime.test-env	installing CRDs
2023-12-08T18:02:28Z	DEBUG	controller-runtime.test-env	reading CRDs from path	{"path": "../../config/crd/bases"}
2023-12-08T18:02:28Z	DEBUG	controller-runtime.test-env	read CRDs from file	{"file": "ray.io_rayclusters.yaml"}
2023-12-08T18:02:28Z	DEBUG	controller-runtime.test-env	read CRDs from file	{"file": "ray.io_rayjobs.yaml"}
2023-12-08T18:02:28Z	DEBUG	controller-runtime.test-env	read CRDs from file	{"file": "ray.io_rayservices.yaml"}
2023-12-08T18:02:28Z	DEBUG	controller-runtime.test-env	installing CRD	{"crd": "rayclusters.ray.io"}
2023-12-08T18:02:29Z	DEBUG	controller-runtime.test-env	installing CRD	{"crd": "rayjobs.ray.io"}
2023-12-08T18:02:30Z	DEBUG	controller-runtime.test-env	installing CRD	{"crd": "rayservices.ray.io"}
2023-12-08T18:02:30Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1"}
2023-12-08T18:02:30Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1alpha1"}
2023-12-08T18:02:30Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1"}
2023-12-08T18:02:30Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1alpha1"}
2023-12-08T18:02:30Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1"}
2023-12-08T18:02:30Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1alpha1"}
2023-12-08T18:02:33Z	DEBUG	controller-runtime.test-env	installing webhooks
2023-12-08T18:02:33Z	INFO	controllers.RayCluster	Starting Reconciler
Setup mock first: 2023-12-08 18:02:33.106692145 +0000 UTC m=+12.269488174


2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "source": "kind source: *v1.RayCluster"}
2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "source": "kind source: *v1.Pod"}
2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "source": "kind source: *v1.Service"}
2023-12-08T18:02:33Z	INFO	Starting Controller	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster"}
2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "source": "kind source: *v1.RayJob"}
2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "source": "kind source: *v1.RayCluster"}
2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "source": "kind source: *v1.Service"}
2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "source": "kind source: *v1.Job"}
2023-12-08T18:02:33Z	INFO	Starting Controller	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob"}
2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "source": "kind source: *v1.RayService"}
2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "source": "kind source: *v1.RayCluster"}
2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "source": "kind source: *v1.Service"}
2023-12-08T18:02:33Z	INFO	Starting EventSource	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "source": "kind source: *v1.Ingress"}
2023-12-08T18:02:33Z	INFO	Starting Controller	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService"}
[38;5;10mâ€¢[0m2023-12-08T18:02:34Z	INFO	Starting workers	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "worker count": 1}
2023-12-08T18:02:34Z	INFO	Starting workers	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "worker count": 1}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Add a finalizer	{"finalizer": "ray.io/rayjob-finalizer"}
2023-12-08T18:02:34Z	INFO	Starting workers	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "worker count": 1}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": true, "RayJob": "rayjob-delayed-dashbaord", "jobId": "", "rayClusterName": "", "jobStatus": ""}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "", "newJobDeploymentStatus": "Initializing"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	RayCluster not found, creating RayCluster!	{"raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	created rayCluster for rayJob	{"rayCluster": {"metadata":{"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default","uid":"b242b802-efea-4134-b0eb-80ce8e83dfc4","resourceVersion":"213","generation":1,"creationTimestamp":"2023-12-08T18:02:34Z","ownerReferences":[{"apiVersion":"ray.io/v1","kind":"RayJob","name":"rayjob-delayed-dashbaord","uid":"1e1d0709-2748-41cd-86de-fe627af1406e","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"ray.test","operation":"Update","apiVersion":"ray.io/v1","time":"2023-12-08T18:02:34Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"1e1d0709-2748-41cd-86de-fe627af1406e\"}":{}}},"f:spec":{".":{},"f:headGroupSpec":{".":{},"f:rayStartParams":{".":{},"f:dashboard-agent-listen-port":{},"f:dashboard-host":{},"f:node-ip-address":{},"f:num-cpus":{},"f:object-store-memory":{},"f:port":{}},"f:template":{".":{},"f:metadata":{".":{},"f:annotations":{".":{},"f:key":{}},"f:labels":{".":{},"f:groupName":{}}},"f:spec":{".":{},"f:containers":{}}}},"f:rayVersion":{},"f:workerGroupSpecs":{}}}}]},"spec":{"headGroupSpec":{"rayStartParams":{"dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"},"template":{"metadata":{"creationTimestamp":null,"labels":{"groupName":"headgroup"},"annotations":{"key":"value"}},"spec":{"containers":[{"name":"ray-head","image":"rayproject/ray:2.8.0","ports":[{"name":"gcs-server","containerPort":6379,"protocol":"TCP"},{"name":"dashboard","containerPort":8265,"protocol":"TCP"},{"name":"head","containerPort":10001,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}]}}},"workerGroupSpecs":[{"groupName":"small-group","replicas":3,"minReplicas":0,"maxReplicas":10000,"rayStartParams":{"dashboard-agent-listen-port":"52365","num-cpus":"1","port":"6379"},"template":{"metadata":{"namespace":"default","creationTimestamp":null,"labels":{"groupName":"small-group"}},"spec":{"containers":[{"name":"ray-worker","image":"rayproject/ray:2.8.0","command":["echo"],"args":["Hello Ray"],"ports":[{"name":"client","containerPort":80,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{}}]}},"scaleStrategy":{}}],"rayVersion":"1.12.1"},"status":{"head":{}}}}
2023-12-08T18:02:34Z	ERROR	controllers.RayJob	Head service is not found	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default", "error": "Service \"rayjob-delayed-dashbaord-raycluster-tpspd-head-svc\" not found"}
github.com/ray-project/kuberay/ray-operator/controllers/ray/utils.FetchHeadServiceURL
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/utils/dashboard_httpclient.go:83
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:191
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:34Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "Initializing", "newJobDeploymentStatus": "WaitForDashboard"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-delayed-dashbaord-raycluster-tpspd"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:34Z	DEBUG	events	Created cluster rayjob-delayed-dashbaord-raycluster-tpspd	{"type": "Normal", "object": {"kind":"RayJob","namespace":"default","name":"rayjob-delayed-dashbaord","uid":"1e1d0709-2748-41cd-86de-fe627af1406e","apiVersion":"ray.io/v1","resourceVersion":"212"}, "reason": "Created"}
2023-12-08T18:02:34Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-delayed-dashbaord","namespace":"default"}, "namespace": "default", "name": "rayjob-delayed-dashbaord", "reconcileID": "d4ccfc68-bbe3-49f0-8296-5efe2053c83d"}
2023-12-08T18:02:34Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-delayed-dashbaord","namespace":"default"}, "namespace": "default", "name": "rayjob-delayed-dashbaord", "reconcileID": "d4ccfc68-bbe3-49f0-8296-5efe2053c83d", "error": "Service \"rayjob-delayed-dashbaord-raycluster-tpspd-head-svc\" not found"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:34Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:34Z	ERROR	controllers.RayJob	Head service is not found	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default", "error": "Service \"rayjob-delayed-dashbaord-raycluster-tpspd-head-svc\" not found"}
github.com/ray-project/kuberay/ray-operator/controllers/ray/utils.FetchHeadServiceURL
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/utils/dashboard_httpclient.go:83
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:191
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:34Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboard", "newJobDeploymentStatus": "WaitForDashboard"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	Pod Service created successfully	{"service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"Found 0 head Pods; creating a head Pod for the RayCluster.": "rayjob-delayed-dashbaord-raycluster-tpspd"}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	Setting pod namespaces	{"namespace": "default"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	head pod labels	{"labels": {"app.kubernetes.io/created-by":"kuberay-operator","app.kubernetes.io/name":"kuberay","groupName":"headgroup","ray.io/cluster":"rayjob-delayed-dashbaord-raycluster-tpspd","ray.io/group":"headgroup","ray.io/identifier":"rayjob-delayed-dashbaord-raycluster-tpspd-head","ray.io/is-ray-node":"yes","ray.io/node-type":"head"}}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "head", "rayStartParams": {"block":"true","dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","metrics-export-port":"8080","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"}, "Ray container resource": {"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start --head  --num-cpus=1  --object-store-memory=100000000  --port=6379  --node-ip-address=127.0.0.1  --metrics-export-port=8080  --dashboard-agent-listen-port=52365  --dashboard-host=0.0.0.0  --block  --memory=2147483648 "}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "head", "generatedCmd": "ulimit -n 65536; ray start --head  --num-cpus=1  --object-store-memory=100000000  --port=6379  --node-ip-address=127.0.0.1  --metrics-export-port=8080  --dashboard-agent-listen-port=52365  --dashboard-host=0.0.0.0  --block  --memory=2147483648 "}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	createHeadPod	{"head pod with name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-"}
2023-12-08T18:02:34Z	DEBUG	events	Created service rayjob-delayed-dashbaord-raycluster-tpspd-head-svc	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-delayed-dashbaord-raycluster-tpspd","uid":"b242b802-efea-4134-b0eb-80ce8e83dfc4","apiVersion":"ray.io/v1","resourceVersion":"213"}, "reason": "Created"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboard", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:02:34Z	DEBUG	events	Created head pod rayjob-delayed-dashbaord-raycluster-tpspd-head-psp7k	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-delayed-dashbaord-raycluster-tpspd","uid":"b242b802-efea-4134-b0eb-80ce8e83dfc4","apiVersion":"ray.io/v1","resourceVersion":"213"}, "reason": "Created"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 0, "diff": 3}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"Number workers to add": 3, "Worker group": "small-group"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 0": "in total 3"}
pod name is too long: len = 61, we will shorten it by offset = 11
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "yed-dashbaord-raycluster-tpspd-worker-small-group-"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 1": "in total 3"}
pod name is too long: len = 61, we will shorten it by offset = 11
2023-12-08T18:02:34Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-delayed-dashbaord","namespace":"default"}, "namespace": "default", "name": "rayjob-delayed-dashbaord", "reconcileID": "8c44648a-25df-4d6c-824b-27c3da37b019"}
2023-12-08T18:02:34Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-delayed-dashbaord","namespace":"default"}, "namespace": "default", "name": "rayjob-delayed-dashbaord", "reconcileID": "8c44648a-25df-4d6c-824b-27c3da37b019", "error": "dashboard is not ready"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --address=rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --port=6379  --dashboard-agent-listen-port=52365  --num-cpus=1 "}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --address=rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --port=6379  --dashboard-agent-listen-port=52365  --num-cpus=1 "}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:34Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-delayed-dashbaord-raycluster-tpspd","uid":"b242b802-efea-4134-b0eb-80ce8e83dfc4","apiVersion":"ray.io/v1","resourceVersion":"213"}, "reason": "Created"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "yed-dashbaord-raycluster-tpspd-worker-small-group-"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 2": "in total 3"}
pod name is too long: len = 61, we will shorten it by offset = 11
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --address=rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --port=6379  --dashboard-agent-listen-port=52365  --num-cpus=1 "}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --address=rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --port=6379  --dashboard-agent-listen-port=52365  --num-cpus=1 "}
2023-12-08T18:02:34Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:34Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-delayed-dashbaord-raycluster-tpspd","uid":"b242b802-efea-4134-b0eb-80ce8e83dfc4","apiVersion":"ray.io/v1","resourceVersion":"213"}, "reason": "Created"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboard", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "yed-dashbaord-raycluster-tpspd-worker-small-group-"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	inconsistentRayClusterStatus	{"detect inconsistency": "old AvailableWorkerReplicas: 0, new AvailableWorkerReplicas: 0, old DesiredWorkerReplicas: 0, new DesiredWorkerReplicas: 3, old MinWorkerReplicas: 0, new MinWorkerReplicas: 0, old MaxWorkerReplicas: 0, new MaxWorkerReplicas: 10000"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	rayClusterReconcile	{"Update CR status": "rayjob-delayed-dashbaord-raycluster-tpspd", "status": {"desiredWorkerReplicas":3,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:02:34Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080"},"head":{"serviceIP":"10.0.0.57"},"observedGeneration":1}}
2023-12-08T18:02:34Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-delayed-dashbaord-raycluster-tpspd","uid":"b242b802-efea-4134-b0eb-80ce8e83dfc4","apiVersion":"ray.io/v1","resourceVersion":"213"}, "reason": "Created"}
2023-12-08T18:02:34Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-delayed-dashbaord","namespace":"default"}, "namespace": "default", "name": "rayjob-delayed-dashbaord", "reconcileID": "bc932aaa-9f54-49e7-afd7-11684f2ba5ad"}
2023-12-08T18:02:34Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-delayed-dashbaord","namespace":"default"}, "namespace": "default", "name": "rayjob-delayed-dashbaord", "reconcileID": "bc932aaa-9f54-49e7-afd7-11684f2ba5ad", "error": "combined error: dashboard is not ready Operation cannot be fulfilled on rayjobs.ray.io \"rayjob-delayed-dashbaord\": the object has been modified; please apply your changes to the latest version and try again", "errorVerbose": "combined error: dashboard is not ready Operation cannot be fulfilled on rayjobs.ray.io \"rayjob-delayed-dashbaord\": the object has been modified; please apply your changes to the latest version and try again\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:566\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:201\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:34Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-delayed-dashbaord-raycluster-tpspd", "seconds": 10}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-delayed-dashbaord-raycluster-tpspd"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-delayed-dashbaord-raycluster-tpspd-head-psp7k", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-delayed-dashbaord-raycluster-tpspd-head-psp7k", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-delayed-dashbaord-raycluster-tpspd-head-psp7k. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-tpspd-worker-small-group-frp4n", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-tpspd-worker-small-group-frp4n. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-tpspd-worker-small-group-ztxjg", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-tpspd-worker-small-group-ztxjg. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-tpspd-worker-small-group-gswq8", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-tpspd-worker-small-group-gswq8. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:34Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-delayed-dashbaord-raycluster-tpspd", "seconds": 10}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:34Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
[38;5;10mâ€¢[0m2023-12-08T18:02:34Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:34Z	INFO	controllers.RayService	No active Ray cluster. RayService operator should prepare a new Ray cluster.
2023-12-08T18:02:34Z	DEBUG	controllers.RayService	Current cluster is unhealthy, prepare to restart.	{"Status": {"activeServiceStatus":{"dashboardStatus":{},"rayClusterStatus":{"head":{}}},"pendingServiceStatus":{"dashboardStatus":{},"rayClusterStatus":{"head":{}}},"observedGeneration":1}}
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m2023-12-08T18:02:34Z	INFO	controllers.RayService	Done reconcileRayCluster update status, enter next loop to create new ray cluster.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	createRayClusterInstance	{"rayClusterInstanceName": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	No pending RayCluster, creating RayCluster.
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	created rayCluster for rayService	{"rayCluster": {"metadata":{"name":"rayservice-sample-raycluster-8xkg7","namespace":"default","uid":"799d158f-d800-46bf-bbb3-3f26adc04dca","resourceVersion":"231","generation":1,"creationTimestamp":"2023-12-08T18:02:36Z","labels":{"app.kubernetes.io/created-by":"rayservice","ray.io/service":"rayservice-sample"},"annotations":{"ray.io/cluster-hash":"076ADR9VKHS5MPJU9KEL1CD0HIIHIOOJ","ray.io/enable-serve-service":"true"},"ownerReferences":[{"apiVersion":"ray.io/v1","kind":"RayService","name":"rayservice-sample","uid":"61b37990-72fd-48e9-a640-5a510691e49d","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"ray.test","operation":"Update","apiVersion":"ray.io/v1","time":"2023-12-08T18:02:36Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:ray.io/cluster-hash":{},"f:ray.io/enable-serve-service":{}},"f:labels":{".":{},"f:app.kubernetes.io/created-by":{},"f:ray.io/service":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"61b37990-72fd-48e9-a640-5a510691e49d\"}":{}}},"f:spec":{".":{},"f:headGroupSpec":{".":{},"f:rayStartParams":{".":{},"f:dashboard-agent-listen-port":{},"f:dashboard-host":{},"f:node-ip-address":{},"f:num-cpus":{},"f:object-store-memory":{},"f:port":{}},"f:template":{".":{},"f:metadata":{".":{},"f:annotations":{".":{},"f:key":{}},"f:labels":{".":{},"f:groupName":{}}},"f:spec":{".":{},"f:containers":{}}}},"f:rayVersion":{},"f:workerGroupSpecs":{}}}}]},"spec":{"headGroupSpec":{"rayStartParams":{"dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"},"template":{"metadata":{"creationTimestamp":null,"labels":{"groupName":"headgroup"},"annotations":{"key":"value"}},"spec":{"containers":[{"name":"ray-head","image":"rayproject/ray:2.8.0","ports":[{"name":"gcs-server","containerPort":6379,"protocol":"TCP"},{"name":"dashboard","containerPort":8265,"protocol":"TCP"},{"name":"head","containerPort":10001,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"},{"name":"serve","containerPort":8000,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"SAMPLE_ENV_VAR","value":"SAMPLE_VALUE"}],"resources":{"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}]}}},"workerGroupSpecs":[{"groupName":"small-group","replicas":3,"minReplicas":0,"maxReplicas":10000,"rayStartParams":{"dashboard-agent-listen-port":"52365","num-cpus":"1","port":"6379"},"template":{"metadata":{"namespace":"default","creationTimestamp":null,"labels":{"groupName":"small-group"}},"spec":{"containers":[{"name":"ray-worker","image":"rayproject/ray:2.8.0","command":["echo"],"args":["Hello Ray"],"ports":[{"name":"client","containerPort":80,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"SAMPLE_ENV_VAR","value":"SAMPLE_VALUE"}],"resources":{}}]}},"scaleStrategy":{}}],"rayVersion":"1.12.1"},"status":{"head":{}}}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	ERROR	controllers.RayService	Failed to check if head Pod is running and ready!	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "Found 0 head pods for RayCluster rayservice-sample-raycluster-8xkg7 in the namespace default"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1044
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:163
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:36Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "Found 0 head pods for RayCluster rayservice-sample-raycluster-8xkg7 in the namespace default"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:164
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:36Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	ERROR	controllers.RayService	Failed to check if head Pod is running and ready!	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "Found 0 head pods for RayCluster rayservice-sample-raycluster-8xkg7 in the namespace default"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1044
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:163
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:36Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "Found 0 head pods for RayCluster rayservice-sample-raycluster-8xkg7 in the namespace default"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:164
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	Pod Service created successfully	{"service name": "rayservice-sample-raycluster-8xkg7-head-svc"}
2023-12-08T18:02:36Z	DEBUG	events	Created service rayservice-sample-raycluster-8xkg7-head-svc	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayservice-sample-raycluster-8xkg7","uid":"799d158f-d800-46bf-bbb3-3f26adc04dca","apiVersion":"ray.io/v1","resourceVersion":"231"}, "reason": "Created"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"Found 0 head Pods; creating a head Pod for the RayCluster.": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	Setting pod namespaces	{"namespace": "default"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	head pod labels	{"labels": {"app.kubernetes.io/created-by":"kuberay-operator","app.kubernetes.io/name":"kuberay","groupName":"headgroup","ray.io/cluster":"rayservice-sample-raycluster-8xkg7","ray.io/group":"headgroup","ray.io/identifier":"rayservice-sample-raycluster-8xkg7-head","ray.io/is-ray-node":"yes","ray.io/node-type":"head"}}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "head", "rayStartParams": {"block":"true","dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","metrics-export-port":"8080","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"}, "Ray container resource": {"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start --head  --dashboard-agent-listen-port=52365  --node-ip-address=127.0.0.1  --num-cpus=1  --object-store-memory=100000000  --metrics-export-port=8080  --memory=2147483648  --dashboard-host=0.0.0.0  --port=6379  --block "}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "head", "generatedCmd": "ulimit -n 65536; ray start --head  --dashboard-agent-listen-port=52365  --node-ip-address=127.0.0.1  --num-cpus=1  --object-store-memory=100000000  --metrics-export-port=8080  --memory=2147483648  --dashboard-host=0.0.0.0  --port=6379  --block "}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	createHeadPod	{"head pod with name": "rayservice-sample-raycluster-8xkg7-head-"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 0, "diff": 3}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"Number workers to add": 3, "Worker group": "small-group"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 0": "in total 3"}
pod name is too long: len = 54, we will shorten it by offset = 4
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:36Z	DEBUG	events	Created head pod rayservice-sample-raycluster-8xkg7-head-skdvp	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayservice-sample-raycluster-8xkg7","uid":"799d158f-d800-46bf-bbb3-3f26adc04dca","apiVersion":"ray.io/v1","resourceVersion":"231"}, "reason": "Created"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "ervice-sample-raycluster-8xkg7-worker-small-group-"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 1": "in total 3"}
pod name is too long: len = 54, we will shorten it by offset = 4
2023-12-08T18:02:36Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayservice-sample-raycluster-8xkg7","uid":"799d158f-d800-46bf-bbb3-3f26adc04dca","apiVersion":"ray.io/v1","resourceVersion":"231"}, "reason": "Created"}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "ervice-sample-raycluster-8xkg7-worker-small-group-"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 2": "in total 3"}
pod name is too long: len = 54, we will shorten it by offset = 4
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:02:36Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:36Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayservice-sample-raycluster-8xkg7","uid":"799d158f-d800-46bf-bbb3-3f26adc04dca","apiVersion":"ray.io/v1","resourceVersion":"231"}, "reason": "Created"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "ervice-sample-raycluster-8xkg7-worker-small-group-"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	inconsistentRayClusterStatus	{"detect inconsistency": "old AvailableWorkerReplicas: 0, new AvailableWorkerReplicas: 0, old DesiredWorkerReplicas: 0, new DesiredWorkerReplicas: 3, old MinWorkerReplicas: 0, new MinWorkerReplicas: 0, old MaxWorkerReplicas: 0, new MaxWorkerReplicas: 10000"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	rayClusterReconcile	{"Update CR status": "rayservice-sample-raycluster-8xkg7", "status": {"desiredWorkerReplicas":3,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:02:36Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080","serve":"8000"},"head":{"serviceIP":"10.0.0.41"},"observedGeneration":1}}
2023-12-08T18:02:36Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayservice-sample-raycluster-8xkg7","uid":"799d158f-d800-46bf-bbb3-3f26adc04dca","apiVersion":"ray.io/v1","resourceVersion":"231"}, "reason": "Created"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": true, "reason": "Nothing has been cached for cluster rayservice-sample-raycluster-8xkg7 with key default/rayservice-sample/rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	updateServeDeployment	{"V1 config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	updateServeDeployment	{"SINGLE_APP json config": "{\"import_path\":\"fruit.deployment_graph\",\"runtime_env\":{\"working_dir\":[\"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"]},\"deployments\":[{\"name\":\"MangoStand\",\"num_replicas\":1,\"user_config\":{\"price\":3},\"ray_actor_options\":{\"num_cpus\":0.1}},{\"name\":\"OrangeStand\",\"num_replicas\":1,\"user_config\":{\"price\":2},\"ray_actor_options\":{\"num_cpus\":0.1}},{\"name\":\"PearStand\",\"num_replicas\":1,\"user_config\":{\"price\":1},\"ray_actor_options\":{\"num_cpus\":0.1}}]}"}
UpdateDeployments fake succeeds.2023-12-08T18:02:36Z	DEBUG	controllers.RayService	updateServeDeployment	{"message": "Cached Serve config for Ray cluster rayservice-sample-raycluster-8xkg7 with key default/rayservice-sample/rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"prev statuses": null, "serve statuses": {"default":{"status":"RUNNING","deployments":{"deep":{"name":"deep","status":"HEALTHY"},"one":{"name":"one","status":"HEALTHY"},"shallow":{"name":"shallow","status":"HEALTHY"}}}}}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"new statuses": {"default":{"status":"RUNNING","healthLastUpdateTime":"2023-12-08T18:02:36Z","serveDeploymentStatuses":{"deep":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"},"one":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"},"shallow":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"}}}}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Check serve health	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "isReady": true, "isActive": false}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	updateRayClusterInfo	{"ActiveRayClusterName": "", "healthyClusterName": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Reconciling the ingress and service resources on the pending Ray cluster.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Ingress is disabled. Skipping ingress reconcilation. You can enable Ingress by setting enableIngress to true in HeadGroupSpec.
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "headService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-head-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/identifier:rayservice-sample-head ray.io/node-type:head ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:dashboard,Protocol:,Port:8265,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:dashboard-agent,Protocol:,Port:52365,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:gcs-server,Protocol:,Port:6379,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:head,Protocol:,Port:10001,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:metrics,Protocol:,Port:8080,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},},Selector:map[string]string{app.kubernetes.io/created-by: kuberay-operator,app.kubernetes.io/name: kuberay,ray.io/cluster: rayservice-sample-raycluster-8xkg7,ray.io/identifier: rayservice-sample-raycluster-8xkg7-head,ray.io/node-type: head,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Create a Kubernetes Service for RayService serviceType headService
2023-12-08T18:02:36Z	DEBUG	events	Controller sent API request to update Serve deployments on cluster rayservice-sample-raycluster-8xkg7	{"type": "Normal", "object": {"kind":"RayService","namespace":"default","name":"rayservice-sample","uid":"61b37990-72fd-48e9-a640-5a510691e49d","apiVersion":"ray.io/v1","resourceVersion":"230"}, "reason": "SubmittedServeDeployment"}
2023-12-08T18:02:36Z	DEBUG	events	The Serve applicaton is now running and healthy.	{"type": "Normal", "object": {"kind":"RayService","namespace":"default","name":"rayservice-sample","uid":"61b37990-72fd-48e9-a640-5a510691e49d","apiVersion":"ray.io/v1","resourceVersion":"230"}, "reason": "Running"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayservice-sample-raycluster-8xkg7", "seconds": 10}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayservice-sample-raycluster-8xkg7-head-svc"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayservice-sample-raycluster-8xkg7-head-skdvp", "Pod status": "Running", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayservice-sample-raycluster-8xkg7-head-skdvp", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayservice-sample-raycluster-8xkg7-head-skdvp. The Pod status is Running, and the Ray container terminated status is nil."}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-8xkg7-worker-small-group-mf69m", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-8xkg7-worker-small-group-mf69m. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-8xkg7-worker-small-group-4jvb9", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-8xkg7-worker-small-group-4jvb9. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-8xkg7-worker-small-group-7rj7t", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-8xkg7-worker-small-group-7rj7t. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:36Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayservice-sample-raycluster-8xkg7", "seconds": 10}
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "serveService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-serve-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/serve:rayservice-sample-serve ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{ray.io/cluster: rayservice-sample-raycluster-8xkg7,ray.io/serve: true,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Create a Kubernetes Service for RayService serviceType serveService
2023-12-08T18:02:36Z	INFO	controllers.RayService	inconsistentRayServiceStatus RayService ServiceStatus changed from Restarting to Running
2023-12-08T18:02:36Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	shouldUpdate	{"should create Serve applications": true, "reason": "No Serve application found in RayCluster rayservice-sample-raycluster-8xkg7, need to create serve applications. A possible reason is the head Pod has crashed and GCS FT is not enabled. Hence, the RayService CR's Serve application status is set to empty in the previous reconcile."}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	updateServeDeployment	{"V1 config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	updateServeDeployment	{"SINGLE_APP json config": "{\"import_path\":\"fruit.deployment_graph\",\"runtime_env\":{\"working_dir\":[\"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"]},\"deployments\":[{\"name\":\"MangoStand\",\"num_replicas\":1,\"user_config\":{\"price\":3},\"ray_actor_options\":{\"num_cpus\":0.1}},{\"name\":\"OrangeStand\",\"num_replicas\":1,\"user_config\":{\"price\":2},\"ray_actor_options\":{\"num_cpus\":0.1}},{\"name\":\"PearStand\",\"num_replicas\":1,\"user_config\":{\"price\":1},\"ray_actor_options\":{\"num_cpus\":0.1}}]}"}
UpdateDeployments fake succeeds.2023-12-08T18:02:36Z	DEBUG	controllers.RayService	updateServeDeployment	{"message": "Cached Serve config for Ray cluster rayservice-sample-raycluster-8xkg7 with key default/rayservice-sample/rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"prev statuses": null, "serve statuses": {"default":{"status":"RUNNING","deployments":{"deep":{"name":"deep","status":"HEALTHY"},"one":{"name":"one","status":"HEALTHY"},"shallow":{"name":"shallow","status":"HEALTHY"}}}}}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"new statuses": {"default":{"status":"RUNNING","healthLastUpdateTime":"2023-12-08T18:02:36Z","serveDeploymentStatuses":{"deep":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"},"one":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"},"shallow":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"}}}}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Check serve health	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "isReady": true, "isActive": false}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	updateRayClusterInfo	{"ActiveRayClusterName": "", "healthyClusterName": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Reconciling the ingress and service resources on the pending Ray cluster.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Ingress is disabled. Skipping ingress reconcilation. You can enable Ingress by setting enableIngress to true in HeadGroupSpec.
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "headService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-head-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/identifier:rayservice-sample-head ray.io/node-type:head ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:dashboard,Protocol:,Port:8265,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:dashboard-agent,Protocol:,Port:52365,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:gcs-server,Protocol:,Port:6379,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:head,Protocol:,Port:10001,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:metrics,Protocol:,Port:8080,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},},Selector:map[string]string{app.kubernetes.io/created-by: kuberay-operator,app.kubernetes.io/name: kuberay,ray.io/cluster: rayservice-sample-raycluster-8xkg7,ray.io/identifier: rayservice-sample-raycluster-8xkg7-head,ray.io/node-type: head,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	RayCluster rayservice-sample-raycluster-8xkg7's headService has already exists, skip Update
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "serveService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:02:36Z	DEBUG	events	Controller sent API request to update Serve deployments on cluster rayservice-sample-raycluster-8xkg7	{"type": "Normal", "object": {"kind":"RayService","namespace":"default","name":"rayservice-sample","uid":"61b37990-72fd-48e9-a640-5a510691e49d","apiVersion":"ray.io/v1","resourceVersion":"230"}, "reason": "SubmittedServeDeployment"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-serve-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/serve:rayservice-sample-serve ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{ray.io/cluster: rayservice-sample-raycluster-8xkg7,ray.io/serve: true,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:02:36Z	DEBUG	events	The Serve applicaton is now running and healthy.	{"type": "Normal", "object": {"kind":"RayService","namespace":"default","name":"rayservice-sample","uid":"61b37990-72fd-48e9-a640-5a510691e49d","apiVersion":"ray.io/v1","resourceVersion":"230"}, "reason": "Running"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	RayCluster rayservice-sample-raycluster-8xkg7's serveService has already exists, skip Update
2023-12-08T18:02:36Z	INFO	controllers.RayService	inconsistentRayServiceStatus RayService ServiceStatus changed from Restarting to Running
2023-12-08T18:02:36Z	ERROR	controllers.RayService	Failed to update RayService status	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "rayServiceInstance": {"apiVersion": "ray.io/v1", "kind": "RayService", "namespace": "default", "name": "rayservice-sample"}, "error": "Operation cannot be fulfilled on rayservices.ray.io \"rayservice-sample\": the object has been modified; please apply your changes to the latest version and try again"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:217
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:36Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "RayService": {"name":"rayservice-sample","namespace":"default"}, "namespace": "default", "name": "rayservice-sample", "reconcileID": "ce116027-7772-46f0-b992-c0d7be6cd2bc"}
2023-12-08T18:02:36Z	ERROR	Reconciler error	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "RayService": {"name":"rayservice-sample","namespace":"default"}, "namespace": "default", "name": "rayservice-sample", "reconcileID": "ce116027-7772-46f0-b992-c0d7be6cd2bc", "error": "Operation cannot be fulfilled on rayservices.ray.io \"rayservice-sample\": the object has been modified; please apply your changes to the latest version and try again"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:36Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:36Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"prev statuses": {"default":{"status":"RUNNING","healthLastUpdateTime":"2023-12-08T18:02:36Z","serveDeploymentStatuses":{"deep":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"},"one":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"},"shallow":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"}}}}, "serve statuses": {"default":{"status":"RUNNING","deployments":{"deep":{"name":"deep","status":"HEALTHY"},"one":{"name":"one","status":"HEALTHY"},"shallow":{"name":"shallow","status":"HEALTHY"}}}}}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"new statuses": {"default":{"status":"RUNNING","healthLastUpdateTime":"2023-12-08T18:02:36Z","serveDeploymentStatuses":{"deep":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"},"one":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"},"shallow":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"}}}}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Check serve health	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "isReady": true, "isActive": true}
2023-12-08T18:02:36Z	DEBUG	controllers.RayService	updateRayClusterInfo	{"ActiveRayClusterName": "rayservice-sample-raycluster-8xkg7", "healthyClusterName": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Reconciling the ingress and service resources on the active Ray cluster. No pending Ray cluster found.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:36Z	INFO	controllers.RayService	Ingress is disabled. Skipping ingress reconcilation. You can enable Ingress by setting enableIngress to true in HeadGroupSpec.
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "headService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-head-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/identifier:rayservice-sample-head ray.io/node-type:head ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:dashboard,Protocol:,Port:8265,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:dashboard-agent,Protocol:,Port:52365,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:gcs-server,Protocol:,Port:6379,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:head,Protocol:,Port:10001,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:metrics,Protocol:,Port:8080,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},},Selector:map[string]string{app.kubernetes.io/created-by: kuberay-operator,app.kubernetes.io/name: kuberay,ray.io/cluster: rayservice-sample-raycluster-8xkg7,ray.io/identifier: rayservice-sample-raycluster-8xkg7-head,ray.io/node-type: head,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	RayCluster rayservice-sample-raycluster-8xkg7's headService has already exists, skip Update
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "serveService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-serve-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/serve:rayservice-sample-serve ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{ray.io/cluster: rayservice-sample-raycluster-8xkg7,ray.io/serve: true,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:02:36Z	INFO	controllers.RayService	RayCluster rayservice-sample-raycluster-8xkg7's serveService has already exists, skip Update
2023-12-08T18:02:36Z	DEBUG	events	The Serve applicaton is now running and healthy.	{"type": "Normal", "object": {"kind":"RayService","namespace":"default","name":"rayservice-sample","uid":"61b37990-72fd-48e9-a640-5a510691e49d","apiVersion":"ray.io/v1","resourceVersion":"253"}, "reason": "Running"}
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Add a finalizer	{"finalizer": "ray.io/rayjob-finalizer"}
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": true, "RayJob": "rayjob-test-default", "jobId": "", "rayClusterName": "", "jobStatus": ""}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "", "newJobDeploymentStatus": "Initializing"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	RayCluster not found, creating RayCluster!	{"raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-9lqzv"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:37Z	INFO	controllers.RayJob	created rayCluster for rayJob	{"rayCluster": {"metadata":{"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default","uid":"78cad130-84a3-435c-bc85-12bc9547857f","resourceVersion":"260","generation":1,"creationTimestamp":"2023-12-08T18:02:37Z","ownerReferences":[{"apiVersion":"ray.io/v1","kind":"RayJob","name":"rayjob-test-default","uid":"8ea9332b-c78d-4d42-af8d-1d43708c71aa","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"ray.test","operation":"Update","apiVersion":"ray.io/v1","time":"2023-12-08T18:02:37Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"8ea9332b-c78d-4d42-af8d-1d43708c71aa\"}":{}}},"f:spec":{".":{},"f:headGroupSpec":{".":{},"f:rayStartParams":{".":{},"f:dashboard-agent-listen-port":{},"f:dashboard-host":{},"f:node-ip-address":{},"f:num-cpus":{},"f:object-store-memory":{},"f:port":{}},"f:template":{".":{},"f:metadata":{".":{},"f:annotations":{".":{},"f:key":{}},"f:labels":{".":{},"f:groupName":{}}},"f:spec":{".":{},"f:containers":{}}}},"f:rayVersion":{},"f:workerGroupSpecs":{}}}}]},"spec":{"headGroupSpec":{"rayStartParams":{"dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"},"template":{"metadata":{"creationTimestamp":null,"labels":{"groupName":"headgroup"},"annotations":{"key":"value"}},"spec":{"containers":[{"name":"ray-head","image":"rayproject/ray:2.8.0","ports":[{"name":"gcs-server","containerPort":6379,"protocol":"TCP"},{"name":"dashboard","containerPort":8265,"protocol":"TCP"},{"name":"head","containerPort":10001,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}]}}},"workerGroupSpecs":[{"groupName":"small-group","replicas":3,"minReplicas":0,"maxReplicas":10000,"rayStartParams":{"dashboard-agent-listen-port":"52365","num-cpus":"1","port":"6379"},"template":{"metadata":{"namespace":"default","creationTimestamp":null,"labels":{"groupName":"small-group"}},"spec":{"containers":[{"name":"ray-worker","image":"rayproject/ray:2.8.0","command":["echo"],"args":["Hello Ray"],"ports":[{"name":"client","containerPort":80,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{}}]}},"scaleStrategy":{}}],"rayVersion":"1.12.1"},"status":{"head":{}}}}
2023-12-08T18:02:37Z	ERROR	controllers.RayJob	Head service is not found	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default", "error": "Service \"rayjob-test-default-raycluster-9lqzv-head-svc\" not found"}
github.com/ray-project/kuberay/ray-operator/controllers/ray/utils.FetchHeadServiceURL
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/utils/dashboard_httpclient.go:83
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:191
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "Initializing", "newJobDeploymentStatus": "WaitForDashboard"}
2023-12-08T18:02:37Z	DEBUG	events	Created cluster rayjob-test-default-raycluster-9lqzv	{"type": "Normal", "object": {"kind":"RayJob","namespace":"default","name":"rayjob-test-default","uid":"8ea9332b-c78d-4d42-af8d-1d43708c71aa","apiVersion":"ray.io/v1","resourceVersion":"259"}, "reason": "Created"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Pod Service created successfully	{"service name": "rayjob-test-default-raycluster-9lqzv-head-svc"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"Found 0 head Pods; creating a head Pod for the RayCluster.": "rayjob-test-default-raycluster-9lqzv"}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	Setting pod namespaces	{"namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	head pod labels	{"labels": {"app.kubernetes.io/created-by":"kuberay-operator","app.kubernetes.io/name":"kuberay","groupName":"headgroup","ray.io/cluster":"rayjob-test-default-raycluster-9lqzv","ray.io/group":"headgroup","ray.io/identifier":"rayjob-test-default-raycluster-9lqzv-head","ray.io/is-ray-node":"yes","ray.io/node-type":"head"}}
2023-12-08T18:02:37Z	DEBUG	events	Created service rayjob-test-default-raycluster-9lqzv-head-svc	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-9lqzv","uid":"78cad130-84a3-435c-bc85-12bc9547857f","apiVersion":"ray.io/v1","resourceVersion":"260"}, "reason": "Created"}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "head", "rayStartParams": {"block":"true","dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","metrics-export-port":"8080","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"}, "Ray container resource": {"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start --head  --object-store-memory=100000000  --port=6379  --block  --num-cpus=1  --node-ip-address=127.0.0.1  --dashboard-agent-listen-port=52365  --metrics-export-port=8080  --memory=2147483648  --dashboard-host=0.0.0.0 "}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "head", "generatedCmd": "ulimit -n 65536; ray start --head  --object-store-memory=100000000  --port=6379  --block  --num-cpus=1  --node-ip-address=127.0.0.1  --dashboard-agent-listen-port=52365  --metrics-export-port=8080  --memory=2147483648  --dashboard-host=0.0.0.0 "}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	createHeadPod	{"head pod with name": "rayjob-test-default-raycluster-9lqzv-head-"}
2023-12-08T18:02:37Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default", "reconcileID": "329f1b88-7d13-4d57-a5de-9ba31984f962"}
2023-12-08T18:02:37Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default", "reconcileID": "329f1b88-7d13-4d57-a5de-9ba31984f962", "error": "Service \"rayjob-test-default-raycluster-9lqzv-head-svc\" not found"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "Initializing", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 0, "diff": 3}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"Number workers to add": 3, "Worker group": "small-group"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 0": "in total 3"}
pod name is too long: len = 56, we will shorten it by offset = 6
-test-default-raycluster-9lqzv-worker-small-group-
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --metrics-export-port=8080  --block  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379 "}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --metrics-export-port=8080  --block  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379 "}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:37Z	DEBUG	events	Created head pod rayjob-test-default-raycluster-9lqzv-head-mj2hk	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-9lqzv","uid":"78cad130-84a3-435c-bc85-12bc9547857f","apiVersion":"ray.io/v1","resourceVersion":"260"}, "reason": "Created"}
2023-12-08T18:02:37Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default", "reconcileID": "e55faf12-f516-4c46-99f9-563ede3e0ce1"}
2023-12-08T18:02:37Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default", "reconcileID": "e55faf12-f516-4c46-99f9-563ede3e0ce1", "error": "combined error: dashboard is not ready Operation cannot be fulfilled on rayjobs.ray.io \"rayjob-test-default\": the object has been modified; please apply your changes to the latest version and try again", "errorVerbose": "combined error: dashboard is not ready Operation cannot be fulfilled on rayjobs.ray.io \"rayjob-test-default\": the object has been modified; please apply your changes to the latest version and try again\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:566\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:201\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboard", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "rtest-default-raycluster-9lqzv-worker-small-group-"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 1": "in total 3"}
pod name is too long: len = 56, we will shorten it by offset = 6
-test-default-raycluster-9lqzv-worker-small-group-
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --address=rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --port=6379 "}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --address=rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --port=6379 "}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:37Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-9lqzv","uid":"78cad130-84a3-435c-bc85-12bc9547857f","apiVersion":"ray.io/v1","resourceVersion":"260"}, "reason": "Created"}
2023-12-08T18:02:37Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default", "reconcileID": "2cfa02cc-8698-44e7-84ac-80e9d423c1c5"}
2023-12-08T18:02:37Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default", "reconcileID": "2cfa02cc-8698-44e7-84ac-80e9d423c1c5", "error": "dashboard is not ready"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboard", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "rtest-default-raycluster-9lqzv-worker-small-group-"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 2": "in total 3"}
pod name is too long: len = 56, we will shorten it by offset = 6
-test-default-raycluster-9lqzv-worker-small-group-
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --block  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080 "}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --block  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080 "}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:37Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-9lqzv","uid":"78cad130-84a3-435c-bc85-12bc9547857f","apiVersion":"ray.io/v1","resourceVersion":"260"}, "reason": "Created"}
2023-12-08T18:02:37Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default", "reconcileID": "3d84ea80-b41e-4173-8b77-cb8c064d9e03"}
2023-12-08T18:02:37Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default", "reconcileID": "3d84ea80-b41e-4173-8b77-cb8c064d9e03", "error": "combined error: dashboard is not ready Operation cannot be fulfilled on rayjobs.ray.io \"rayjob-test-default\": the object has been modified; please apply your changes to the latest version and try again", "errorVerbose": "combined error: dashboard is not ready Operation cannot be fulfilled on rayjobs.ray.io \"rayjob-test-default\": the object has been modified; please apply your changes to the latest version and try again\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:566\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:201\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "rtest-default-raycluster-9lqzv-worker-small-group-"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	inconsistentRayClusterStatus	{"detect inconsistency": "old AvailableWorkerReplicas: 0, new AvailableWorkerReplicas: 0, old DesiredWorkerReplicas: 0, new DesiredWorkerReplicas: 3, old MinWorkerReplicas: 0, new MinWorkerReplicas: 0, old MaxWorkerReplicas: 0, new MaxWorkerReplicas: 10000"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	rayClusterReconcile	{"Update CR status": "rayjob-test-default-raycluster-9lqzv", "status": {"desiredWorkerReplicas":3,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:02:37Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080"},"head":{"serviceIP":"10.0.0.150"},"observedGeneration":1}}
2023-12-08T18:02:37Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-9lqzv","uid":"78cad130-84a3-435c-bc85-12bc9547857f","apiVersion":"ray.io/v1","resourceVersion":"260"}, "reason": "Created"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-9lqzv", "seconds": 10}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-9lqzv"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-9lqzv-head-svc"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-9lqzv-head-mj2hk. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-4t5np", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-4t5np. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-7kq6n", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-7kq6n. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-2dc47", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-2dc47. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-9lqzv", "seconds": 10}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Update RayCluster replica	{"RayCluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-9lqzv"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-9lqzv-head-svc"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-9lqzv-head-mj2hk. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 4, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 4}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-2dc47", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-2dc47. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-7kq6n", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-7kq6n. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-4t5np", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-4t5np. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 4, "runningPods": 3, "diff": 1}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"Number workers to add": 1, "Worker group": "small-group"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 0": "in total 1"}
pod name is too long: len = 56, we will shorten it by offset = 6
-test-default-raycluster-9lqzv-worker-small-group-
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:02:37Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "rtest-default-raycluster-9lqzv-worker-small-group-"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	inconsistentRayClusterStatus	{"detect inconsistency": "old AvailableWorkerReplicas: 0, new AvailableWorkerReplicas: 0, old DesiredWorkerReplicas: 3, new DesiredWorkerReplicas: 4, old MinWorkerReplicas: 0, new MinWorkerReplicas: 0, old MaxWorkerReplicas: 10000, new MaxWorkerReplicas: 10000"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	rayClusterReconcile	{"Update CR status": "rayjob-test-default-raycluster-9lqzv", "status": {"desiredWorkerReplicas":4,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:02:37Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080"},"head":{"serviceIP":"10.0.0.150"},"observedGeneration":2}}
2023-12-08T18:02:37Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-9lqzv","uid":"78cad130-84a3-435c-bc85-12bc9547857f","apiVersion":"ray.io/v1","resourceVersion":"277"}, "reason": "Created"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-9lqzv", "seconds": 10}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-9lqzv"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-9lqzv-head-svc"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-9lqzv-head-mj2hk. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 4, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 4}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-7kq6n", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-7kq6n. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-2dc47", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-2dc47. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-gpn4j", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-gpn4j. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-4t5np", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-4t5np. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 4, "runningPods": 4, "diff": 0}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	inconsistentRayClusterStatus	{"detect inconsistency": "old AvailableWorkerReplicas: 0, new AvailableWorkerReplicas: 0, old DesiredWorkerReplicas: 3, new DesiredWorkerReplicas: 4, old MinWorkerReplicas: 0, new MinWorkerReplicas: 0, old MaxWorkerReplicas: 10000, new MaxWorkerReplicas: 10000"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	rayClusterReconcile	{"Update CR status": "rayjob-test-default-raycluster-9lqzv", "status": {"desiredWorkerReplicas":4,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:02:37Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080"},"head":{"serviceIP":"10.0.0.150"},"observedGeneration":2}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:37Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Got error when updating status	{"cluster name": "rayjob-test-default-raycluster-9lqzv", "error": "Operation cannot be fulfilled on rayclusters.ray.io \"rayjob-test-default-raycluster-9lqzv\": the object has been modified; please apply your changes to the latest version and try again", "RayCluster": {"kind":"RayCluster","apiVersion":"ray.io/v1","metadata":{"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default","uid":"78cad130-84a3-435c-bc85-12bc9547857f","resourceVersion":"277","generation":2,"creationTimestamp":"2023-12-08T18:02:37Z","ownerReferences":[{"apiVersion":"ray.io/v1","kind":"RayJob","name":"rayjob-test-default","uid":"8ea9332b-c78d-4d42-af8d-1d43708c71aa","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"ray.test","operation":"Update","apiVersion":"ray.io/v1","time":"2023-12-08T18:02:37Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"8ea9332b-c78d-4d42-af8d-1d43708c71aa\"}":{}}},"f:spec":{".":{},"f:headGroupSpec":{".":{},"f:rayStartParams":{".":{},"f:dashboard-agent-listen-port":{},"f:dashboard-host":{},"f:node-ip-address":{},"f:num-cpus":{},"f:object-store-memory":{},"f:port":{}},"f:template":{".":{},"f:metadata":{".":{},"f:annotations":{".":{},"f:key":{}},"f:labels":{".":{},"f:groupName":{}}},"f:spec":{".":{},"f:containers":{}}}},"f:rayVersion":{},"f:workerGroupSpecs":{}}}},{"manager":"ray.test","operation":"Update","apiVersion":"ray.io/v1","time":"2023-12-08T18:02:37Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{".":{},"f:desiredWorkerReplicas":{},"f:endpoints":{".":{},"f:dashboard":{},"f:dashboard-agent":{},"f:gcs-server":{},"f:head":{},"f:metrics":{}},"f:head":{".":{},"f:serviceIP":{}},"f:lastUpdateTime":{},"f:maxWorkerReplicas":{},"f:observedGeneration":{}}},"subresource":"status"}]},"spec":{"headGroupSpec":{"rayStartParams":{"dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"},"template":{"metadata":{"creationTimestamp":null,"labels":{"groupName":"headgroup"},"annotations":{"key":"value"}},"spec":{"containers":[{"name":"ray-head","image":"rayproject/ray:2.8.0","ports":[{"name":"gcs-server","containerPort":6379,"protocol":"TCP"},{"name":"dashboard","containerPort":8265,"protocol":"TCP"},{"name":"head","containerPort":10001,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}]}}},"workerGroupSpecs":[{"groupName":"small-group","replicas":4,"minReplicas":0,"maxReplicas":10000,"rayStartParams":{"dashboard-agent-listen-port":"52365","num-cpus":"1","port":"6379"},"template":{"metadata":{"namespace":"default","creationTimestamp":null,"labels":{"groupName":"small-group"}},"spec":{"containers":[{"name":"ray-worker","image":"rayproject/ray:2.8.0","command":["echo"],"args":["Hello Ray"],"ports":[{"name":"client","containerPort":80,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{}}]}},"scaleStrategy":{}}],"rayVersion":"1.12.1"},"status":{"desiredWorkerReplicas":4,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:02:37Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080"},"head":{"serviceIP":"10.0.0.150"},"observedGeneration":2}}}
2023-12-08T18:02:37Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "RayCluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default-raycluster-9lqzv", "reconcileID": "548bc20f-5704-4501-91b3-6086d67560c3"}
2023-12-08T18:02:37Z	ERROR	Reconciler error	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "RayCluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default-raycluster-9lqzv", "reconcileID": "548bc20f-5704-4501-91b3-6086d67560c3", "error": "Operation cannot be fulfilled on rayclusters.ray.io \"rayjob-test-default-raycluster-9lqzv\": the object has been modified; please apply your changes to the latest version and try again"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-9lqzv"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-9lqzv-head-svc"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-9lqzv-head-mj2hk. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 4, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 4}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-7kq6n", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-7kq6n. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-2dc47", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-2dc47. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-gpn4j", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-gpn4j. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-4t5np", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-4t5np. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 4, "runningPods": 4, "diff": 0}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:37Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-9lqzv", "seconds": 10}
[38;5;10mâ€¢[0m2023-12-08T18:02:38Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:38Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:38Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:38Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:38Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:38Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:38Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:38Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"prev statuses": {"default":{"status":"RUNNING","healthLastUpdateTime":"2023-12-08T18:02:36Z","serveDeploymentStatuses":{"deep":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"},"one":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"},"shallow":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:36Z"}}}}, "serve statuses": {"default":{"status":"RUNNING","deployments":{"deep":{"name":"deep","status":"HEALTHY"},"one":{"name":"one","status":"HEALTHY"},"shallow":{"name":"shallow","status":"HEALTHY"}}}}}
2023-12-08T18:02:38Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"new statuses": {"default":{"status":"RUNNING","healthLastUpdateTime":"2023-12-08T18:02:38Z","serveDeploymentStatuses":{"deep":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:38Z"},"one":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:38Z"},"shallow":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:02:38Z"}}}}}
2023-12-08T18:02:38Z	INFO	controllers.RayService	Check serve health	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "isReady": true, "isActive": true}
2023-12-08T18:02:38Z	DEBUG	controllers.RayService	updateRayClusterInfo	{"ActiveRayClusterName": "rayservice-sample-raycluster-8xkg7", "healthyClusterName": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:38Z	INFO	controllers.RayService	Reconciling the ingress and service resources on the active Ray cluster. No pending Ray cluster found.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:38Z	INFO	controllers.RayService	Ingress is disabled. Skipping ingress reconcilation. You can enable Ingress by setting enableIngress to true in HeadGroupSpec.
2023-12-08T18:02:38Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "headService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:02:38Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-head-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/identifier:rayservice-sample-head ray.io/node-type:head ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:dashboard,Protocol:,Port:8265,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:dashboard-agent,Protocol:,Port:52365,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:gcs-server,Protocol:,Port:6379,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:head,Protocol:,Port:10001,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:metrics,Protocol:,Port:8080,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},},Selector:map[string]string{app.kubernetes.io/created-by: kuberay-operator,app.kubernetes.io/name: kuberay,ray.io/cluster: rayservice-sample-raycluster-8xkg7,ray.io/identifier: rayservice-sample-raycluster-8xkg7-head,ray.io/node-type: head,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:02:38Z	INFO	controllers.RayService	RayCluster rayservice-sample-raycluster-8xkg7's headService has already exists, skip Update
2023-12-08T18:02:38Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "serveService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:02:38Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-serve-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/serve:rayservice-sample-serve ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{ray.io/cluster: rayservice-sample-raycluster-8xkg7,ray.io/serve: true,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:02:38Z	INFO	controllers.RayService	RayCluster rayservice-sample-raycluster-8xkg7's serveService has already exists, skip Update
2023-12-08T18:02:38Z	DEBUG	events	The Serve applicaton is now running and healthy.	{"type": "Normal", "object": {"kind":"RayService","namespace":"default","name":"rayservice-sample","uid":"61b37990-72fd-48e9-a640-5a510691e49d","apiVersion":"ray.io/v1","resourceVersion":"253"}, "reason": "Running"}

[38;5;243m------------------------------[0m
[38;5;9mâ€¢ [FAILED] [1.000 seconds][0m
[0mInside the default namespace [38;5;243mWhen creating a rayjob [38;5;9m[1m[It] Dashboard URL should be set[0m
[38;5;243m/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller_test.go:239[0m

  [38;5;9m[FAILED] Timed out after 1.000s.
  Dashboard URL = 
  Expected
      <string>: 
  to have prefix
      <string>: rayjob-test-default[0m
  [38;5;9mIn [1m[It][0m[38;5;9m at: [1m/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller_test.go:242[0m [38;5;243m@ 12/08/23 18:02:39.419[0m
[38;5;243m------------------------------[0m
2023-12-08T18:02:39Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	Add a finalizer	{"finalizer": "ray.io/rayjob-finalizer"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": true, "RayJob": "rayjob-test-default-2", "jobId": "", "rayClusterName": "", "jobStatus": ""}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "", "newJobDeploymentStatus": "Initializing"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "Initializing", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:39Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default-2","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default-2", "reconcileID": "271af12e-7f5c-4938-9cb2-aee6736703b3"}
2023-12-08T18:02:39Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default-2","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default-2", "reconcileID": "271af12e-7f5c-4938-9cb2-aee6736703b3", "error": "dashboard is not ready"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:39Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-8d9wq", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-8d9wq", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:02:39Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
[38;5;10mâ€¢[0m2023-12-08T18:02:40Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-shhft\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-fmkvz\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:40Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:40Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:40Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:40Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:40Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:40Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:40Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:40Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:40Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:42Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:02:42Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-8d9wq", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:42Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:42Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:42Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:42Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:42Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-2-8d9wq\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:42Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:42Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:42Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:42Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:42Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:42Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:42Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:42Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:42Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:43Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-shhft\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-fmkvz\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:43Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-delayed-dashbaord-raycluster-tpspd"}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc"}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-delayed-dashbaord-raycluster-tpspd-head-psp7k", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-delayed-dashbaord-raycluster-tpspd-head-psp7k", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-delayed-dashbaord-raycluster-tpspd-head-psp7k. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-tpspd-worker-small-group-gswq8", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-tpspd-worker-small-group-gswq8. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-tpspd-worker-small-group-frp4n", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-tpspd-worker-small-group-frp4n. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-tpspd-worker-small-group-ztxjg", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-tpspd-worker-small-group-ztxjg. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:44Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-delayed-dashbaord-raycluster-tpspd", "seconds": 10}
2023-12-08T18:02:44Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:44Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:44Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:44Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:44Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:44Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:44Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:44Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:45Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:02:45Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-8d9wq", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:45Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:45Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:45Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:45Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:45Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-2-8d9wq\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:45Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-shhft\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-fmkvz\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:46Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayservice-sample-raycluster-8xkg7-head-svc"}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayservice-sample-raycluster-8xkg7-head-skdvp", "Pod status": "Running", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayservice-sample-raycluster-8xkg7-head-skdvp", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayservice-sample-raycluster-8xkg7-head-skdvp. The Pod status is Running, and the Ray container terminated status is nil."}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-8xkg7-worker-small-group-7rj7t", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-8xkg7-worker-small-group-7rj7t. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-8xkg7-worker-small-group-mf69m", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-8xkg7-worker-small-group-mf69m. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-8xkg7-worker-small-group-4jvb9", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-8xkg7-worker-small-group-4jvb9. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:46Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayservice-sample-raycluster-8xkg7", "seconds": 10}
2023-12-08T18:02:46Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:46Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:46Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:46Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:46Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:46Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:46Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:46Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-9lqzv"}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-9lqzv-head-svc"}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-9lqzv-head-mj2hk. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 4, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 4}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-7kq6n", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-7kq6n. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-2dc47", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-2dc47. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-gpn4j", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-gpn4j. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-4t5np", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-4t5np. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 4, "runningPods": 4, "diff": 0}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:47Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-9lqzv", "seconds": 10}
2023-12-08T18:02:48Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:02:48Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-8d9wq", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:48Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:48Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:48Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:48Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:48Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-2-8d9wq\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:48Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:48Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:48Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:48Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:48Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:48Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:48Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:48Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:48Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:49Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-shhft\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-fmkvz\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:49Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:50Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:50Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:50Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:50Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:50Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:50Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:50Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:50Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:51Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:02:51Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-8d9wq", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:51Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:51Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:51Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:51Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:51Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-2-8d9wq\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:51Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-shhft\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-fmkvz\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:52Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:52Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:52Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:52Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:52Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:52Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:52Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:52Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:52Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:54Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:02:54Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-8d9wq", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:54Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:54Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:54Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:54Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:54Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-2-8d9wq\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:54Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-delayed-dashbaord-raycluster-tpspd"}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc"}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-delayed-dashbaord-raycluster-tpspd-head-psp7k", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-delayed-dashbaord-raycluster-tpspd-head-psp7k", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-delayed-dashbaord-raycluster-tpspd-head-psp7k. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-tpspd-worker-small-group-frp4n", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-tpspd-worker-small-group-frp4n. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-tpspd-worker-small-group-ztxjg", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-tpspd-worker-small-group-ztxjg. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-tpspd-worker-small-group-gswq8", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-tpspd-worker-small-group-gswq8. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:54Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-delayed-dashbaord-raycluster-tpspd", "seconds": 10}
2023-12-08T18:02:54Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:54Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:54Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:54Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:54Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:54Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:54Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:54Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:55Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-shhft\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-fmkvz\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:55Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayservice-sample-raycluster-8xkg7-head-svc"}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayservice-sample-raycluster-8xkg7-head-skdvp", "Pod status": "Running", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayservice-sample-raycluster-8xkg7-head-skdvp", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayservice-sample-raycluster-8xkg7-head-skdvp. The Pod status is Running, and the Ray container terminated status is nil."}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-8xkg7-worker-small-group-mf69m", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-8xkg7-worker-small-group-mf69m. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-8xkg7-worker-small-group-4jvb9", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-8xkg7-worker-small-group-4jvb9. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-8xkg7-worker-small-group-7rj7t", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-8xkg7-worker-small-group-7rj7t. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:56Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayservice-sample-raycluster-8xkg7", "seconds": 10}
2023-12-08T18:02:56Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:56Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:56Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:56Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:56Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:56Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:56Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:56Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:02:57Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:02:57Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-8d9wq", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:57Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:57Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:57Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:57Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:57Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-2-8d9wq\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:57Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-9lqzv"}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-9lqzv-head-svc"}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-9lqzv-head-mj2hk", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-9lqzv-head-mj2hk. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 4, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 4}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-7kq6n", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-7kq6n. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-2dc47", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-2dc47. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-gpn4j", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-gpn4j. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-9lqzv-worker-small-group-4t5np", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-9lqzv-worker-small-group-4t5np. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 4, "runningPods": 4, "diff": 0}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:02:57Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-9lqzv", "seconds": 10}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-shhft", "rayClusterName": "rayjob-test-default-raycluster-9lqzv", "jobStatus": "PENDING"}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-9lqzv","namespace":"default"}}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-9lqzv-head-svc", "namespace": "default"}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-test-default-shhft\": dial tcp: lookup rayjob-test-default-raycluster-9lqzv-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-fmkvz", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-tpspd", "jobStatus": "PENDING"}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-tpspd","namespace":"default"}}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc", "namespace": "default"}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-fmkvz\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-tpspd-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:02:58Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:02:58Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:58Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:02:58Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:02:58Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-8xkg7"}
2023-12-08T18:02:58Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-8xkg7-head-svc", "namespace": "default"}
2023-12-08T18:02:58Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:02:58Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-8xkg7", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:02:58Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-8xkg7-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33571/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33571: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227


[38;5;9m[1mSummarizing 1 Failure:[0m
  [38;5;9m[FAIL][0m [0mInside the default namespace [38;5;243mWhen creating a rayjob [38;5;9m[1m[It] Dashboard URL should be set[0m
  [38;5;243m/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller_test.go:242[0m

[38;5;9m[1mRan 13 of 13 Specs in 39.061 seconds[0m
[38;5;9m[1mFAIL![0m -- [38;5;10m[1m12 Passed[0m | [38;5;9m[1m1 Failed[0m | [38;5;11m[1m0 Pending[0m | [38;5;14m[1m0 Skipped[0m
--- FAIL: TestAPIs (39.06s)
FAIL
coverage: 42.9% of statements
FAIL	github.com/ray-project/kuberay/ray-operator/controllers/ray	39.177s
=== RUN   TestCreatePodGroup
--- PASS: TestCreatePodGroup (0.00s)
PASS
coverage: 9.1% of statements
ok  	github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler/volcano	0.057s	coverage: 9.1% of statements
=== RUN   TestBuildIngressForHeadServiceWithoutIngressClass
time="2023-12-08T18:02:20Z" level=warning msg="ingress class annotation is not set for cluster default/raycluster-sample"
--- PASS: TestBuildIngressForHeadServiceWithoutIngressClass (0.00s)
=== RUN   TestBuildIngressForHeadService
--- PASS: TestBuildIngressForHeadService (0.00s)
=== RUN   TestGetDecodedRuntimeEnv
--- PASS: TestGetDecodedRuntimeEnv (0.00s)
=== RUN   TestGetRuntimeEnvJsonFromBase64
--- PASS: TestGetRuntimeEnvJsonFromBase64 (0.00s)
=== RUN   TestGetRuntimeEnvJsonFromYAML
--- PASS: TestGetRuntimeEnvJsonFromYAML (0.00s)
=== RUN   TestGetRuntimeEnvJsonErrorWithBothFields
--- PASS: TestGetRuntimeEnvJsonErrorWithBothFields (0.00s)
=== RUN   TestGetBaseRayJobCommand
--- PASS: TestGetBaseRayJobCommand (0.00s)
=== RUN   TestGetMetadataJson
--- PASS: TestGetMetadataJson (0.00s)
=== RUN   TestGetK8sJobCommand
--- PASS: TestGetK8sJobCommand (0.00s)
=== RUN   TestGetK8sJobCommandWithYAML
--- PASS: TestGetK8sJobCommandWithYAML (0.00s)
=== RUN   TestMetadataRaisesErrorBeforeRay26
--- PASS: TestMetadataRaisesErrorBeforeRay26 (0.00s)
=== RUN   TestGetDefaultSubmitterTemplate
--- PASS: TestGetDefaultSubmitterTemplate (0.00s)
=== RUN   TestAddEmptyDirVolumes
--- PASS: TestAddEmptyDirVolumes (0.00s)
=== RUN   TestGetHeadPort
--- PASS: TestGetHeadPort (0.00s)
=== RUN   TestBuildPod
--- PASS: TestBuildPod (0.00s)
=== RUN   TestBuildPod_WithOverwriteCommand
--- PASS: TestBuildPod_WithOverwriteCommand (0.00s)
=== RUN   TestBuildPod_WithAutoscalerEnabled
--- PASS: TestBuildPod_WithAutoscalerEnabled (0.00s)
=== RUN   TestBuildPod_WithCreatedByRayService
--- PASS: TestBuildPod_WithCreatedByRayService (0.00s)
=== RUN   TestBuildPod_WithGcsFtEnabled
--- PASS: TestBuildPod_WithGcsFtEnabled (0.00s)
=== RUN   TestBuildPodWithAutoscalerOptions
--- PASS: TestBuildPodWithAutoscalerOptions (0.00s)
=== RUN   TestHeadPodTemplate_WithAutoscalingEnabled
label value is too long: len = 205, we will shorten it by offset = 142
pod name is too long: len = 200, we will shorten it by offset = 150
pod name is too long: len = 200, we will shorten it by offset = 150
--- PASS: TestHeadPodTemplate_WithAutoscalingEnabled (0.00s)
=== RUN   TestHeadPodTemplate_AutoscalerImage
--- PASS: TestHeadPodTemplate_AutoscalerImage (0.00s)
=== RUN   TestHeadPodTemplate_WithNoServiceAccount
--- PASS: TestHeadPodTemplate_WithNoServiceAccount (0.00s)
=== RUN   TestHeadPodTemplate_WithServiceAccountNoAutoscaling
--- PASS: TestHeadPodTemplate_WithServiceAccountNoAutoscaling (0.00s)
=== RUN   TestHeadPodTemplate_WithServiceAccount
--- PASS: TestHeadPodTemplate_WithServiceAccount (0.00s)
=== RUN   TestValidateHeadRayStartParams_OK
--- PASS: TestValidateHeadRayStartParams_OK (0.00s)
=== RUN   TestValidateHeadRayStartParams_ValidWithObjectStoreMemoryError
--- PASS: TestValidateHeadRayStartParams_ValidWithObjectStoreMemoryError (0.00s)
=== RUN   TestValidateHeadRayStartParams_InvalidObjectStoreMemory
--- PASS: TestValidateHeadRayStartParams_InvalidObjectStoreMemory (0.00s)
=== RUN   TestCleanupInvalidVolumeMounts
--- PASS: TestCleanupInvalidVolumeMounts (0.00s)
=== RUN   TestDefaultWorkerPodTemplateWithName
--- PASS: TestDefaultWorkerPodTemplateWithName (0.00s)
=== RUN   TestDefaultHeadPodTemplateWithConfigurablePorts
--- PASS: TestDefaultHeadPodTemplateWithConfigurablePorts (0.00s)
=== RUN   TestDefaultWorkerPodTemplateWithConfigurablePorts
--- PASS: TestDefaultWorkerPodTemplateWithConfigurablePorts (0.00s)
=== RUN   TestDefaultInitContainer
--- PASS: TestDefaultInitContainer (0.00s)
=== RUN   TestDefaultInitContainerImagePullPolicy
=== RUN   TestDefaultInitContainerImagePullPolicy/Always
=== RUN   TestDefaultInitContainerImagePullPolicy/IfNotPresent
=== RUN   TestDefaultInitContainerImagePullPolicy/Never
--- PASS: TestDefaultInitContainerImagePullPolicy (0.00s)
    --- PASS: TestDefaultInitContainerImagePullPolicy/Always (0.00s)
    --- PASS: TestDefaultInitContainerImagePullPolicy/IfNotPresent (0.00s)
    --- PASS: TestDefaultInitContainerImagePullPolicy/Never (0.00s)
=== RUN   TestSetMissingRayStartParamsAddress
--- PASS: TestSetMissingRayStartParamsAddress (0.00s)
=== RUN   TestSetMissingRayStartParamsMetricsExportPort
--- PASS: TestSetMissingRayStartParamsMetricsExportPort (0.00s)
=== RUN   TestSetMissingRayStartParamsBlock
--- PASS: TestSetMissingRayStartParamsBlock (0.00s)
=== RUN   TestSetMissingRayStartParamsDashboardHost
--- PASS: TestSetMissingRayStartParamsDashboardHost (0.00s)
=== RUN   TestSetMissingRayStartParamsAgentListenPort
--- PASS: TestSetMissingRayStartParamsAgentListenPort (0.00s)
=== RUN   TestGetCustomWorkerInitImage
--- PASS: TestGetCustomWorkerInitImage (0.00s)
=== RUN   TestGetEnableProbesInjection
--- PASS: TestGetEnableProbesInjection (0.00s)
=== RUN   TestInitHealthProbe
--- PASS: TestInitHealthProbe (0.00s)
=== RUN   TestBuildRoleBindingSubjectAndRoleRefName
pod name is too long: len = 200, we will shorten it by offset = 150
pod name is too long: len = 200, we will shorten it by offset = 150
=== RUN   TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_with_head_group_service_account
=== RUN   TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_without_head_group_service_account
=== RUN   TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_with_a_long_name_and_without_head_group_service_account
pod name is too long: len = 200, we will shorten it by offset = 150
pod name is too long: len = 200, we will shorten it by offset = 150
--- PASS: TestBuildRoleBindingSubjectAndRoleRefName (0.00s)
    --- PASS: TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_with_head_group_service_account (0.00s)
    --- PASS: TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_without_head_group_service_account (0.00s)
    --- PASS: TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_with_a_long_name_and_without_head_group_service_account (0.00s)
=== RUN   TestBuildRouteForHeadService
--- PASS: TestBuildRouteForHeadService (0.00s)
=== RUN   TestBuildServiceForHeadPod
--- PASS: TestBuildServiceForHeadPod (0.00s)
=== RUN   TestBuildServiceForHeadPodWithAppNameLabel
--- PASS: TestBuildServiceForHeadPodWithAppNameLabel (0.00s)
=== RUN   TestBuildServiceForHeadPodWithAnnotations
--- PASS: TestBuildServiceForHeadPodWithAnnotations (0.00s)
=== RUN   TestGetPortsFromCluster
--- PASS: TestGetPortsFromCluster (0.00s)
=== RUN   TestGetServicePortsWithMetricsPort
--- PASS: TestGetServicePortsWithMetricsPort (0.00s)
=== RUN   TestUserSpecifiedHeadService
default label: key=ray.io/node-type, value=head
default label: key=app.kubernetes.io/name, value=kuberay
default label: key=app.kubernetes.io/created-by, value=kuberay-operator
default label: key=ray.io/cluster, value=raycluster-sample
default label: key=ray.io/identifier, value=raycluster-sample-head
    service_test.go:374: head service: {
          "metadata": {
            "name": "user-custom-name",
            "namespace": "default",
            "creationTimestamp": null,
            "labels": {
              "app.kubernetes.io/created-by": "kuberay-operator",
              "app.kubernetes.io/name": "kuberay",
              "ray.io/cluster": "userTemplateClusterName",
              "ray.io/identifier": "raycluster-sample-head",
              "ray.io/node-type": "head",
              "userLabelKey": "userLabelValue"
            },
            "annotations": {
              "HeadServiceAnnotationKey1": "HeadServiceAnnotationValue1",
              "HeadServiceAnnotationKey2": "HeadServiceAnnotationValue2",
              "userAnnotationKey": "userAnnotationValue"
            }
          },
          "spec": {
            "ports": [
              {
                "name": "userPort",
                "port": 12345,
                "targetPort": 0
              },
              {
                "name": "client",
                "port": 98765,
                "targetPort": 0
              },
              {
                "name": "gcs",
                "appProtocol": "tcp",
                "port": 6379,
                "targetPort": 0
              },
              {
                "name": "8265-port",
                "appProtocol": "tcp",
                "port": 8265,
                "targetPort": 0
              },
              {
                "name": "serve",
                "appProtocol": "tcp",
                "port": 8000,
                "targetPort": 0
              },
              {
                "name": "metrics",
                "appProtocol": "tcp",
                "port": 8080,
                "targetPort": 0
              }
            ],
            "selector": {
              "app.kubernetes.io/created-by": "kuberay-operator",
              "app.kubernetes.io/name": "kuberay",
              "ray.io/cluster": "userTemplateClusterName",
              "ray.io/identifier": "raycluster-sample-head",
              "ray.io/node-type": "head"
            },
            "type": "LoadBalancer"
          },
          "status": {
            "loadBalancer": {}
          }
        }
--- PASS: TestUserSpecifiedHeadService (0.00s)
=== RUN   TestNilMapDoesntErrorInUserSpecifiedHeadService
--- PASS: TestNilMapDoesntErrorInUserSpecifiedHeadService (0.00s)
=== RUN   TestBuildServiceForHeadPodPortsOrder
--- PASS: TestBuildServiceForHeadPodPortsOrder (0.00s)
=== RUN   TestBuildServeServiceForRayService
--- PASS: TestBuildServeServiceForRayService (0.00s)
=== RUN   TestBuildServeServiceForRayCluster
--- PASS: TestBuildServeServiceForRayCluster (0.00s)
=== RUN   TestBuildServeServiceForRayService_WithoutServePort
--- PASS: TestBuildServeServiceForRayService_WithoutServePort (0.00s)
=== RUN   TestUserSpecifiedServeService
--- PASS: TestUserSpecifiedServeService (0.00s)
PASS
coverage: 85.7% of statements
ok  	github.com/ray-project/kuberay/ray-operator/controllers/ray/common	0.063s	coverage: 85.7% of statements
=== RUN   TestGetClusterDomainName
=== RUN   TestGetClusterDomainName/all_good_from_env
=== RUN   TestGetClusterDomainName/No_env_set
--- PASS: TestGetClusterDomainName (0.00s)
    --- PASS: TestGetClusterDomainName/all_good_from_env (0.00s)
    --- PASS: TestGetClusterDomainName/No_env_set (0.00s)
=== RUN   TestBefore
--- PASS: TestBefore (0.00s)
=== RUN   TestStatus
--- PASS: TestStatus (0.00s)
=== RUN   TestCheckAllPodsRunning
--- PASS: TestCheckAllPodsRunning (0.00s)
=== RUN   TestCheckName
pod name is too long: len = 69, we will shorten it by offset = 19
-ca41-e903-fc3ae634b18e-lazer090scholar-director-s
pod name is too long: len = 59, we will shorten it by offset = 9
--- PASS: TestCheckName (0.00s)
=== RUN   TestGetHeadGroupServiceAccountName
=== RUN   TestGetHeadGroupServiceAccountName/Ray_cluster_with_head_group_service_account
=== RUN   TestGetHeadGroupServiceAccountName/Ray_cluster_without_head_group_service_account
--- PASS: TestGetHeadGroupServiceAccountName (0.00s)
    --- PASS: TestGetHeadGroupServiceAccountName/Ray_cluster_with_head_group_service_account (0.00s)
    --- PASS: TestGetHeadGroupServiceAccountName/Ray_cluster_without_head_group_service_account (0.00s)
=== RUN   TestReconcile_CheckNeedRemoveOldPod
--- PASS: TestReconcile_CheckNeedRemoveOldPod (0.00s)
=== RUN   TestCalculateAvailableReplicas
--- PASS: TestCalculateAvailableReplicas (0.00s)
=== RUN   TestFindContainerPort
--- PASS: TestFindContainerPort (0.00s)
=== RUN   TestGenerateHeadServiceName
--- PASS: TestGenerateHeadServiceName (0.00s)
=== RUN   TestGetWorkerGroupDesiredReplicas
time="2023-12-08T18:02:20Z" level=warning msg="minReplicas (5) is greater than maxReplicas (1), using maxReplicas as desired replicas. Please fix this to avoid any unexpected behaviors."
--- PASS: TestGetWorkerGroupDesiredReplicas (0.00s)
=== RUN   TestCalculateDesiredReplicas
=== RUN   TestCalculateDesiredReplicas/Both_groups'_Replicas_are_nil
=== RUN   TestCalculateDesiredReplicas/Group1's_Replicas_is_smaller_than_MinReplicas,_and_Group2's_Replicas_is_more_than_MaxReplicas.
=== RUN   TestCalculateDesiredReplicas/Group1's_Replicas_is_more_than_MaxReplicas.
--- PASS: TestCalculateDesiredReplicas (0.00s)
    --- PASS: TestCalculateDesiredReplicas/Both_groups'_Replicas_are_nil (0.00s)
    --- PASS: TestCalculateDesiredReplicas/Group1's_Replicas_is_smaller_than_MinReplicas,_and_Group2's_Replicas_is_more_than_MaxReplicas. (0.00s)
    --- PASS: TestCalculateDesiredReplicas/Group1's_Replicas_is_more_than_MaxReplicas. (0.00s)
=== RUN   TestUtils
Running Suite: Utils Suite - /home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/utils
===========================================================================================
Random Seed: [1m1702058540[0m

Will run [1m4[0m of [1m4[0m specs
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m

[38;5;10m[1mRan 4 of 4 Specs in 0.001 seconds[0m
[38;5;10m[1mSUCCESS![0m -- [38;5;10m[1m4 Passed[0m | [38;5;9m[1m0 Failed[0m | [38;5;11m[1m0 Pending[0m | [38;5;14m[1m0 Skipped[0m
--- PASS: TestUtils (0.00s)
PASS
coverage: 29.3% of statements
ok  	github.com/ray-project/kuberay/ray-operator/controllers/ray/utils	0.079s	coverage: 29.3% of statements
FAIL
