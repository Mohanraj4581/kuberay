test -s /home/ubuntu/go/src/kuberay/ray-operator/bin/controller-gen || GOBIN=/home/ubuntu/go/src/kuberay/ray-operator/bin go install sigs.k8s.io/controller-tools/cmd/controller-gen@v0.13.0
/home/ubuntu/go/src/kuberay/ray-operator/bin/controller-gen "crd:maxDescLen=0,generateEmbeddedObjectMeta=true,allowDangerousTypes=true" rbac:roleName=kuberay-operator webhook paths="./..." output:crd:artifacts:config=config/crd/bases
/home/ubuntu/go/src/kuberay/ray-operator/bin/controller-gen object:headerFile="hack/boilerplate.go.txt" paths="./..."
go fmt ./...
go vet ./...
test -s /home/ubuntu/go/src/kuberay/ray-operator/bin/setup-envtest || GOBIN=/home/ubuntu/go/src/kuberay/ray-operator/bin go install sigs.k8s.io/controller-runtime/tools/setup-envtest@latest
KUBEBUILDER_ASSETS="/home/ubuntu/go/src/kuberay/ray-operator/bin/k8s/1.24.2-linux-amd64" go test github.com/ray-project/kuberay/ray-operator github.com/ray-project/kuberay/ray-operator/apis/ray/v1 github.com/ray-project/kuberay/ray-operator/apis/ray/v1alpha1 github.com/ray-project/kuberay/ray-operator/controllers/ray github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler/interface github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler/volcano github.com/ray-project/kuberay/ray-operator/controllers/ray/common github.com/ray-project/kuberay/ray-operator/controllers/ray/utils github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/fake github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/scheme github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/typed/ray/v1 github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/typed/ray/v1/fake github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/internalinterfaces github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/ray github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/ray/v1 github.com/ray-project/kuberay/ray-operator/pkg/client/listers/ray/v1 -coverprofile cover.out -test.v
?   	github.com/ray-project/kuberay/ray-operator	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler/interface	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/fake	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/scheme	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/typed/ray/v1	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/typed/ray/v1/fake	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/internalinterfaces	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/ray	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/ray/v1	[no test files]
?   	github.com/ray-project/kuberay/ray-operator/pkg/client/listers/ray/v1	[no test files]
=== RUN   TestMarshalling
--- PASS: TestMarshalling (0.00s)
=== RUN   TestMarshallingRayJob
--- PASS: TestMarshallingRayJob (0.00s)
=== RUN   TestMarshallingRayService
--- PASS: TestMarshallingRayService (0.00s)
=== RUN   TestAPIs
Running Suite: Webhook Suite - /home/ubuntu/go/src/kuberay/ray-operator/apis/ray/v1
===================================================================================
Random Seed: [1m1702058425[0m

Will run [1m1[0m of [1m1[0m specs
[38;5;10mâ€¢[0m

[38;5;10m[1mRan 1 of 1 Specs in 14.348 seconds[0m
[38;5;10m[1mSUCCESS![0m -- [38;5;10m[1m1 Passed[0m | [38;5;9m[1m0 Failed[0m | [38;5;11m[1m0 Pending[0m | [38;5;14m[1m0 Skipped[0m
--- PASS: TestAPIs (14.36s)
PASS
coverage: 9.5% of statements
ok  	github.com/ray-project/kuberay/ray-operator/apis/ray/v1	14.442s	coverage: 9.5% of statements
=== RUN   TestMarshalling
--- PASS: TestMarshalling (0.00s)
=== RUN   TestMarshallingRayJob
--- PASS: TestMarshallingRayJob (0.00s)
=== RUN   TestMarshallingRayService
--- PASS: TestMarshallingRayService (0.00s)
PASS
coverage: 0.7% of statements
ok  	github.com/ray-project/kuberay/ray-operator/apis/ray/v1alpha1	0.054s	coverage: 0.7% of statements
=== RUN   TestAPIs
Running Suite: Controller Suite - /home/ubuntu/go/src/kuberay/ray-operator/controllers/ray
==========================================================================================
Random Seed: [1m1702058427[0m

Will run [1m13[0m of [1m13[0m specs
2023-12-08T18:00:27Z	DEBUG	controller-runtime.test-env	starting control plane
2023-12-08T18:00:34Z	DEBUG	controller-runtime.test-env	installing CRDs
2023-12-08T18:00:34Z	DEBUG	controller-runtime.test-env	reading CRDs from path	{"path": "../../config/crd/bases"}
2023-12-08T18:00:34Z	DEBUG	controller-runtime.test-env	read CRDs from file	{"file": "ray.io_rayclusters.yaml"}
2023-12-08T18:00:34Z	DEBUG	controller-runtime.test-env	read CRDs from file	{"file": "ray.io_rayjobs.yaml"}
2023-12-08T18:00:35Z	DEBUG	controller-runtime.test-env	read CRDs from file	{"file": "ray.io_rayservices.yaml"}
2023-12-08T18:00:35Z	DEBUG	controller-runtime.test-env	installing CRD	{"crd": "rayservices.ray.io"}
2023-12-08T18:00:35Z	DEBUG	controller-runtime.test-env	installing CRD	{"crd": "rayclusters.ray.io"}
2023-12-08T18:00:36Z	DEBUG	controller-runtime.test-env	installing CRD	{"crd": "rayjobs.ray.io"}
2023-12-08T18:00:37Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1"}
2023-12-08T18:00:37Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1alpha1"}
2023-12-08T18:00:37Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1"}
2023-12-08T18:00:37Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1alpha1"}
2023-12-08T18:00:37Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1"}
2023-12-08T18:00:37Z	DEBUG	controller-runtime.test-env	adding API in waitlist	{"GV": "ray.io/v1alpha1"}
2023-12-08T18:00:39Z	DEBUG	controller-runtime.test-env	installing webhooks
2023-12-08T18:00:39Z	INFO	controllers.RayCluster	Starting Reconciler
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "source": "kind source: *v1.RayCluster"}
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "source": "kind source: *v1.Pod"}
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "source": "kind source: *v1.Service"}
2023-12-08T18:00:39Z	INFO	Starting Controller	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster"}
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "source": "kind source: *v1.RayJob"}
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "source": "kind source: *v1.RayCluster"}
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "source": "kind source: *v1.Service"}
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "source": "kind source: *v1.Job"}
2023-12-08T18:00:39Z	INFO	Starting Controller	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob"}
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "source": "kind source: *v1.RayService"}
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "source": "kind source: *v1.RayCluster"}
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "source": "kind source: *v1.Service"}
2023-12-08T18:00:39Z	INFO	Starting EventSource	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "source": "kind source: *v1.Ingress"}
2023-12-08T18:00:39Z	INFO	Starting Controller	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService"}
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m2023-12-08T18:00:41Z	INFO	Starting workers	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "worker count": 1}
2023-12-08T18:00:41Z	INFO	Starting workers	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "worker count": 1}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Add a finalizer	{"finalizer": "ray.io/rayjob-finalizer"}
2023-12-08T18:00:41Z	INFO	Starting workers	{"controller": "rayservice", "controllerGroup": "ray.io", "controllerKind": "RayService", "worker count": 1}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": true, "RayJob": "rayjob-test-default", "jobId": "", "rayClusterName": "", "jobStatus": ""}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "", "newJobDeploymentStatus": "Initializing"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	RayCluster not found, creating RayCluster!	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	created rayCluster for rayJob	{"rayCluster": {"metadata":{"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default","uid":"75b3fa66-5128-429d-96ec-ca95a684a771","resourceVersion":"213","generation":1,"creationTimestamp":"2023-12-08T18:00:41Z","ownerReferences":[{"apiVersion":"ray.io/v1","kind":"RayJob","name":"rayjob-test-default","uid":"e60e8896-5c53-4788-b2d1-2379b58702c6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"ray.test","operation":"Update","apiVersion":"ray.io/v1","time":"2023-12-08T18:00:41Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"e60e8896-5c53-4788-b2d1-2379b58702c6\"}":{}}},"f:spec":{".":{},"f:headGroupSpec":{".":{},"f:rayStartParams":{".":{},"f:dashboard-agent-listen-port":{},"f:dashboard-host":{},"f:node-ip-address":{},"f:num-cpus":{},"f:object-store-memory":{},"f:port":{}},"f:template":{".":{},"f:metadata":{".":{},"f:annotations":{".":{},"f:key":{}},"f:labels":{".":{},"f:groupName":{}}},"f:spec":{".":{},"f:containers":{}}}},"f:rayVersion":{},"f:workerGroupSpecs":{}}}}]},"spec":{"headGroupSpec":{"rayStartParams":{"dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"},"template":{"metadata":{"creationTimestamp":null,"labels":{"groupName":"headgroup"},"annotations":{"key":"value"}},"spec":{"containers":[{"name":"ray-head","image":"rayproject/ray:2.8.0","ports":[{"name":"gcs-server","containerPort":6379,"protocol":"TCP"},{"name":"dashboard","containerPort":8265,"protocol":"TCP"},{"name":"head","containerPort":10001,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}]}}},"workerGroupSpecs":[{"groupName":"small-group","replicas":3,"minReplicas":0,"maxReplicas":10000,"rayStartParams":{"dashboard-agent-listen-port":"52365","num-cpus":"1","port":"6379"},"template":{"metadata":{"namespace":"default","creationTimestamp":null,"labels":{"groupName":"small-group"}},"spec":{"containers":[{"name":"ray-worker","image":"rayproject/ray:2.8.0","command":["echo"],"args":["Hello Ray"],"ports":[{"name":"client","containerPort":80,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{}}]}},"scaleStrategy":{}}],"rayVersion":"1.12.1"},"status":{"head":{}}}}
2023-12-08T18:00:41Z	ERROR	controllers.RayJob	Head service is not found	{"head service name": "rayjob-test-default-raycluster-kvjgm-head-svc", "namespace": "default", "error": "Service \"rayjob-test-default-raycluster-kvjgm-head-svc\" not found"}
github.com/ray-project/kuberay/ray-operator/controllers/ray/utils.FetchHeadServiceURL
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/utils/dashboard_httpclient.go:83
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:191
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:41Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "Initializing", "newJobDeploymentStatus": "WaitForDashboard"}
2023-12-08T18:00:41Z	DEBUG	events	Created cluster rayjob-test-default-raycluster-kvjgm	{"type": "Normal", "object": {"kind":"RayJob","namespace":"default","name":"rayjob-test-default","uid":"e60e8896-5c53-4788-b2d1-2379b58702c6","apiVersion":"ray.io/v1","resourceVersion":"212"}, "reason": "Created"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:41Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default", "reconcileID": "0f2c085d-9050-419b-9df0-36f67ae5f82b"}
2023-12-08T18:00:41Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default", "reconcileID": "0f2c085d-9050-419b-9df0-36f67ae5f82b", "error": "Service \"rayjob-test-default-raycluster-kvjgm-head-svc\" not found"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:41Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:41Z	ERROR	controllers.RayJob	Head service is not found	{"head service name": "rayjob-test-default-raycluster-kvjgm-head-svc", "namespace": "default", "error": "Service \"rayjob-test-default-raycluster-kvjgm-head-svc\" not found"}
github.com/ray-project/kuberay/ray-operator/controllers/ray/utils.FetchHeadServiceURL
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/utils/dashboard_httpclient.go:83
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:191
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:41Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboard", "newJobDeploymentStatus": "WaitForDashboard"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-kvjgm-head-svc", "namespace": "default"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Update RayJob status	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Pod Service created successfully	{"service name": "rayjob-test-default-raycluster-kvjgm-head-svc"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"Found 0 head Pods; creating a head Pod for the RayCluster.": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	Setting pod namespaces	{"namespace": "default"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	head pod labels	{"labels": {"app.kubernetes.io/created-by":"kuberay-operator","app.kubernetes.io/name":"kuberay","groupName":"headgroup","ray.io/cluster":"rayjob-test-default-raycluster-kvjgm","ray.io/group":"headgroup","ray.io/identifier":"rayjob-test-default-raycluster-kvjgm-head","ray.io/is-ray-node":"yes","ray.io/node-type":"head"}}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "head", "rayStartParams": {"block":"true","dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","metrics-export-port":"8080","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"}, "Ray container resource": {"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start --head  --metrics-export-port=8080  --block  --object-store-memory=100000000  --port=6379  --dashboard-host=0.0.0.0  --memory=2147483648  --dashboard-agent-listen-port=52365  --node-ip-address=127.0.0.1  --num-cpus=1 "}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "head", "generatedCmd": "ulimit -n 65536; ray start --head  --metrics-export-port=8080  --block  --object-store-memory=100000000  --port=6379  --dashboard-host=0.0.0.0  --memory=2147483648  --dashboard-agent-listen-port=52365  --node-ip-address=127.0.0.1  --num-cpus=1 "}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	createHeadPod	{"head pod with name": "rayjob-test-default-raycluster-kvjgm-head-"}
2023-12-08T18:00:41Z	DEBUG	events	Created service rayjob-test-default-raycluster-kvjgm-head-svc	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-kvjgm","uid":"75b3fa66-5128-429d-96ec-ca95a684a771","apiVersion":"ray.io/v1","resourceVersion":"213"}, "reason": "Created"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 0, "diff": 3}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"Number workers to add": 3, "Worker group": "small-group"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 0": "in total 3"}
pod name is too long: len = 56, we will shorten it by offset = 6
-test-default-raycluster-kvjgm-worker-small-group-
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --num-cpus=1  --port=6379  --dashboard-agent-listen-port=52365  --address=rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --num-cpus=1  --port=6379  --dashboard-agent-listen-port=52365  --address=rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:41Z	DEBUG	events	Created head pod rayjob-test-default-raycluster-kvjgm-head-69rll	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-kvjgm","uid":"75b3fa66-5128-429d-96ec-ca95a684a771","apiVersion":"ray.io/v1","resourceVersion":"213"}, "reason": "Created"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "rtest-default-raycluster-kvjgm-worker-small-group-"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 1": "in total 3"}
pod name is too long: len = 56, we will shorten it by offset = 6
-test-default-raycluster-kvjgm-worker-small-group-
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --address=rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --num-cpus=1  --port=6379 "}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --address=rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --num-cpus=1  --port=6379 "}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:41Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-kvjgm","uid":"75b3fa66-5128-429d-96ec-ca95a684a771","apiVersion":"ray.io/v1","resourceVersion":"213"}, "reason": "Created"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "rtest-default-raycluster-kvjgm-worker-small-group-"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 2": "in total 3"}
pod name is too long: len = 56, we will shorten it by offset = 6
-test-default-raycluster-kvjgm-worker-small-group-
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:41Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-kvjgm","uid":"75b3fa66-5128-429d-96ec-ca95a684a771","apiVersion":"ray.io/v1","resourceVersion":"213"}, "reason": "Created"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "rtest-default-raycluster-kvjgm-worker-small-group-"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	inconsistentRayClusterStatus	{"detect inconsistency": "old AvailableWorkerReplicas: 0, new AvailableWorkerReplicas: 0, old DesiredWorkerReplicas: 0, new DesiredWorkerReplicas: 3, old MinWorkerReplicas: 0, new MinWorkerReplicas: 0, old MaxWorkerReplicas: 0, new MaxWorkerReplicas: 10000"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	rayClusterReconcile	{"Update CR status": "rayjob-test-default-raycluster-kvjgm", "status": {"desiredWorkerReplicas":3,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:00:41Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080"},"head":{"serviceIP":"10.0.0.40"},"observedGeneration":1}}
2023-12-08T18:00:41Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-kvjgm","uid":"75b3fa66-5128-429d-96ec-ca95a684a771","apiVersion":"ray.io/v1","resourceVersion":"213"}, "reason": "Created"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-kvjgm", "seconds": 10}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-kvjgm-head-svc"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-kvjgm-head-69rll. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-sr27m", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-sr27m. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-kqxw4", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-kqxw4. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-hm8q6", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-hm8q6. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	inconsistentRayClusterStatus	{"detect inconsistency": "old AvailableWorkerReplicas: 0, new AvailableWorkerReplicas: 0, old DesiredWorkerReplicas: 0, new DesiredWorkerReplicas: 3, old MinWorkerReplicas: 0, new MinWorkerReplicas: 0, old MaxWorkerReplicas: 0, new MaxWorkerReplicas: 10000"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	rayClusterReconcile	{"Update CR status": "rayjob-test-default-raycluster-kvjgm", "status": {"desiredWorkerReplicas":3,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:00:41Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080"},"head":{"serviceIP":"10.0.0.40"},"observedGeneration":1}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Got error when updating status	{"cluster name": "rayjob-test-default-raycluster-kvjgm", "error": "Operation cannot be fulfilled on rayclusters.ray.io \"rayjob-test-default-raycluster-kvjgm\": the object has been modified; please apply your changes to the latest version and try again", "RayCluster": {"kind":"RayCluster","apiVersion":"ray.io/v1","metadata":{"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default","uid":"75b3fa66-5128-429d-96ec-ca95a684a771","resourceVersion":"213","generation":1,"creationTimestamp":"2023-12-08T18:00:41Z","ownerReferences":[{"apiVersion":"ray.io/v1","kind":"RayJob","name":"rayjob-test-default","uid":"e60e8896-5c53-4788-b2d1-2379b58702c6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"ray.test","operation":"Update","apiVersion":"ray.io/v1","time":"2023-12-08T18:00:41Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"e60e8896-5c53-4788-b2d1-2379b58702c6\"}":{}}},"f:spec":{".":{},"f:headGroupSpec":{".":{},"f:rayStartParams":{".":{},"f:dashboard-agent-listen-port":{},"f:dashboard-host":{},"f:node-ip-address":{},"f:num-cpus":{},"f:object-store-memory":{},"f:port":{}},"f:template":{".":{},"f:metadata":{".":{},"f:annotations":{".":{},"f:key":{}},"f:labels":{".":{},"f:groupName":{}}},"f:spec":{".":{},"f:containers":{}}}},"f:rayVersion":{},"f:workerGroupSpecs":{}}}}]},"spec":{"headGroupSpec":{"rayStartParams":{"dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"},"template":{"metadata":{"creationTimestamp":null,"labels":{"groupName":"headgroup"},"annotations":{"key":"value"}},"spec":{"containers":[{"name":"ray-head","image":"rayproject/ray:2.8.0","ports":[{"name":"gcs-server","containerPort":6379,"protocol":"TCP"},{"name":"dashboard","containerPort":8265,"protocol":"TCP"},{"name":"head","containerPort":10001,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}]}}},"workerGroupSpecs":[{"groupName":"small-group","replicas":3,"minReplicas":0,"maxReplicas":10000,"rayStartParams":{"dashboard-agent-listen-port":"52365","num-cpus":"1","port":"6379"},"template":{"metadata":{"namespace":"default","creationTimestamp":null,"labels":{"groupName":"small-group"}},"spec":{"containers":[{"name":"ray-worker","image":"rayproject/ray:2.8.0","command":["echo"],"args":["Hello Ray"],"ports":[{"name":"client","containerPort":80,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{}}]}},"scaleStrategy":{}}],"rayVersion":"1.12.1"},"status":{"desiredWorkerReplicas":3,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:00:41Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080"},"head":{"serviceIP":"10.0.0.40"},"observedGeneration":1}}}
2023-12-08T18:00:41Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "RayCluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default-raycluster-kvjgm", "reconcileID": "4fdfd71f-b858-49d4-b029-ba9355aeb44d"}
2023-12-08T18:00:41Z	ERROR	Reconciler error	{"controller": "raycluster-controller", "controllerGroup": "ray.io", "controllerKind": "RayCluster", "RayCluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default-raycluster-kvjgm", "reconcileID": "4fdfd71f-b858-49d4-b029-ba9355aeb44d", "error": "Operation cannot be fulfilled on rayclusters.ray.io \"rayjob-test-default-raycluster-kvjgm\": the object has been modified; please apply your changes to the latest version and try again"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-kvjgm-head-svc"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-kvjgm-head-69rll. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-hm8q6", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-hm8q6. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-sr27m", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-sr27m. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-kqxw4", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-kqxw4. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-kvjgm", "seconds": 10}
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m2023-12-08T18:00:41Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Update RayCluster replica	{"RayCluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-kvjgm-head-svc"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-kvjgm-head-69rll. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 4, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 4}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-sr27m", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-sr27m. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-kqxw4", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-kqxw4. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-hm8q6", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-hm8q6. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 4, "runningPods": 3, "diff": 1}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"Number workers to add": 1, "Worker group": "small-group"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 0": "in total 1"}
pod name is too long: len = 56, we will shorten it by offset = 6
-test-default-raycluster-kvjgm-worker-small-group-
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --address=rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --port=6379 "}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --address=rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --port=6379 "}
2023-12-08T18:00:41Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "rtest-default-raycluster-kvjgm-worker-small-group-"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	inconsistentRayClusterStatus	{"detect inconsistency": "old AvailableWorkerReplicas: 0, new AvailableWorkerReplicas: 0, old DesiredWorkerReplicas: 3, new DesiredWorkerReplicas: 4, old MinWorkerReplicas: 0, new MinWorkerReplicas: 0, old MaxWorkerReplicas: 10000, new MaxWorkerReplicas: 10000"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	rayClusterReconcile	{"Update CR status": "rayjob-test-default-raycluster-kvjgm", "status": {"desiredWorkerReplicas":4,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:00:41Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080"},"head":{"serviceIP":"10.0.0.40"},"observedGeneration":2}}
2023-12-08T18:00:41Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-test-default-raycluster-kvjgm","uid":"75b3fa66-5128-429d-96ec-ca95a684a771","apiVersion":"ray.io/v1","resourceVersion":"230"}, "reason": "Created"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:41Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-kvjgm", "seconds": 10}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-kvjgm-head-svc"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-kvjgm-head-69rll. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 4, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 4}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-sr27m", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-sr27m. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-kqxw4", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-kqxw4. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-hm8q6", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-hm8q6. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-l74qb", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-l74qb. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 4, "runningPods": 4, "diff": 0}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:00:41Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-kvjgm", "seconds": 10}
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m2023-12-08T18:00:42Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	Add a finalizer	{"finalizer": "ray.io/rayjob-finalizer"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": true, "RayJob": "rayjob-test-default-2", "jobId": "", "rayClusterName": "", "jobStatus": ""}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "", "newJobDeploymentStatus": "Initializing"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-kvjgm-head-svc", "namespace": "default"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	Update RayJob status	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-b4g78", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-test-default-raycluster-kvjgm-head-svc", "namespace": "default"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	Update RayJob status	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:42Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default-2","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default-2", "reconcileID": "4470837b-df0f-4ff6-8602-4233a883e7ca"}
2023-12-08T18:00:42Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-test-default-2","namespace":"default"}, "namespace": "default", "name": "rayjob-test-default-2", "reconcileID": "4470837b-df0f-4ff6-8602-4233a883e7ca", "error": "Operation cannot be fulfilled on rayjobs.ray.io \"rayjob-test-default-2\": the object has been modified; please apply your changes to the latest version and try again"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:42Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-b4g78", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-b4g78", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:42Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
[38;5;10mâ€¢[0m2023-12-08T18:00:42Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:42Z	INFO	controllers.RayService	No active Ray cluster. RayService operator should prepare a new Ray cluster.
2023-12-08T18:00:42Z	DEBUG	controllers.RayService	Current cluster is unhealthy, prepare to restart.	{"Status": {"activeServiceStatus":{"dashboardStatus":{},"rayClusterStatus":{"head":{}}},"pendingServiceStatus":{"dashboardStatus":{},"rayClusterStatus":{"head":{}}},"observedGeneration":1}}
2023-12-08T18:00:42Z	INFO	controllers.RayService	Done reconcileRayCluster update status, enter next loop to create new ray cluster.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m2023-12-08T18:00:44Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:44Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:44Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:44Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:44Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:44Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:44Z	DEBUG	controllers.RayService	createRayClusterInstance	{"rayClusterInstanceName": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:44Z	DEBUG	controllers.RayService	No pending RayCluster, creating RayCluster.
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:44Z	DEBUG	controllers.RayService	created rayCluster for rayService	{"rayCluster": {"metadata":{"name":"rayservice-sample-raycluster-g79cg","namespace":"default","uid":"95e6a72a-8af5-4c20-953d-66ef4c9b4feb","resourceVersion":"241","generation":1,"creationTimestamp":"2023-12-08T18:00:44Z","labels":{"app.kubernetes.io/created-by":"rayservice","ray.io/service":"rayservice-sample"},"annotations":{"ray.io/cluster-hash":"076ADR9VKHS5MPJU9KEL1CD0HIIHIOOJ","ray.io/enable-serve-service":"true"},"ownerReferences":[{"apiVersion":"ray.io/v1","kind":"RayService","name":"rayservice-sample","uid":"4a8484cc-467c-4f14-8a8c-1aacfcfebd2a","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"ray.test","operation":"Update","apiVersion":"ray.io/v1","time":"2023-12-08T18:00:44Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:ray.io/cluster-hash":{},"f:ray.io/enable-serve-service":{}},"f:labels":{".":{},"f:app.kubernetes.io/created-by":{},"f:ray.io/service":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4a8484cc-467c-4f14-8a8c-1aacfcfebd2a\"}":{}}},"f:spec":{".":{},"f:headGroupSpec":{".":{},"f:rayStartParams":{".":{},"f:dashboard-agent-listen-port":{},"f:dashboard-host":{},"f:node-ip-address":{},"f:num-cpus":{},"f:object-store-memory":{},"f:port":{}},"f:template":{".":{},"f:metadata":{".":{},"f:annotations":{".":{},"f:key":{}},"f:labels":{".":{},"f:groupName":{}}},"f:spec":{".":{},"f:containers":{}}}},"f:rayVersion":{},"f:workerGroupSpecs":{}}}}]},"spec":{"headGroupSpec":{"rayStartParams":{"dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"},"template":{"metadata":{"creationTimestamp":null,"labels":{"groupName":"headgroup"},"annotations":{"key":"value"}},"spec":{"containers":[{"name":"ray-head","image":"rayproject/ray:2.8.0","ports":[{"name":"gcs-server","containerPort":6379,"protocol":"TCP"},{"name":"dashboard","containerPort":8265,"protocol":"TCP"},{"name":"head","containerPort":10001,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"},{"name":"serve","containerPort":8000,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"SAMPLE_ENV_VAR","value":"SAMPLE_VALUE"}],"resources":{"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}]}}},"workerGroupSpecs":[{"groupName":"small-group","replicas":3,"minReplicas":0,"maxReplicas":10000,"rayStartParams":{"dashboard-agent-listen-port":"52365","num-cpus":"1","port":"6379"},"template":{"metadata":{"namespace":"default","creationTimestamp":null,"labels":{"groupName":"small-group"}},"spec":{"containers":[{"name":"ray-worker","image":"rayproject/ray:2.8.0","command":["echo"],"args":["Hello Ray"],"ports":[{"name":"client","containerPort":80,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"SAMPLE_ENV_VAR","value":"SAMPLE_VALUE"}],"resources":{}}]}},"scaleStrategy":{}}],"rayVersion":"1.12.1"},"status":{"head":{}}}}
2023-12-08T18:00:44Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:44Z	ERROR	controllers.RayService	Failed to check if head Pod is running and ready!	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "Found 0 head pods for RayCluster rayservice-sample-raycluster-g79cg in the namespace default"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1044
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:163
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:44Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "Found 0 head pods for RayCluster rayservice-sample-raycluster-g79cg in the namespace default"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:164
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:44Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:44Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:44Z	ERROR	controllers.RayService	Failed to check if head Pod is running and ready!	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "Found 0 head pods for RayCluster rayservice-sample-raycluster-g79cg in the namespace default"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1044
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:163
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:44Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "Found 0 head pods for RayCluster rayservice-sample-raycluster-g79cg in the namespace default"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:164
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	Pod Service created successfully	{"service name": "rayservice-sample-raycluster-g79cg-head-svc"}
2023-12-08T18:00:44Z	DEBUG	events	Created service rayservice-sample-raycluster-g79cg-head-svc	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayservice-sample-raycluster-g79cg","uid":"95e6a72a-8af5-4c20-953d-66ef4c9b4feb","apiVersion":"ray.io/v1","resourceVersion":"241"}, "reason": "Created"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"Found 0 head Pods; creating a head Pod for the RayCluster.": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	Setting pod namespaces	{"namespace": "default"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	head pod labels	{"labels": {"app.kubernetes.io/created-by":"kuberay-operator","app.kubernetes.io/name":"kuberay","groupName":"headgroup","ray.io/cluster":"rayservice-sample-raycluster-g79cg","ray.io/group":"headgroup","ray.io/identifier":"rayservice-sample-raycluster-g79cg-head","ray.io/is-ray-node":"yes","ray.io/node-type":"head"}}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "head", "rayStartParams": {"block":"true","dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","metrics-export-port":"8080","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"}, "Ray container resource": {"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start --head  --node-ip-address=127.0.0.1  --dashboard-agent-listen-port=52365  --dashboard-host=0.0.0.0  --block  --memory=2147483648  --num-cpus=1  --object-store-memory=100000000  --port=6379  --metrics-export-port=8080 "}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "head", "generatedCmd": "ulimit -n 65536; ray start --head  --node-ip-address=127.0.0.1  --dashboard-agent-listen-port=52365  --dashboard-host=0.0.0.0  --block  --memory=2147483648  --num-cpus=1  --object-store-memory=100000000  --port=6379  --metrics-export-port=8080 "}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	createHeadPod	{"head pod with name": "rayservice-sample-raycluster-g79cg-head-"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 0, "diff": 3}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"Number workers to add": 3, "Worker group": "small-group"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 0": "in total 3"}
pod name is too long: len = 54, we will shorten it by offset = 4
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:44Z	DEBUG	events	Created head pod rayservice-sample-raycluster-g79cg-head-tjjnf	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayservice-sample-raycluster-g79cg","uid":"95e6a72a-8af5-4c20-953d-66ef4c9b4feb","apiVersion":"ray.io/v1","resourceVersion":"241"}, "reason": "Created"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "ervice-sample-raycluster-g79cg-worker-small-group-"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 1": "in total 3"}
pod name is too long: len = 54, we will shorten it by offset = 4
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --dashboard-agent-listen-port=52365 "}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --dashboard-agent-listen-port=52365 "}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:44Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayservice-sample-raycluster-g79cg","uid":"95e6a72a-8af5-4c20-953d-66ef4c9b4feb","apiVersion":"ray.io/v1","resourceVersion":"241"}, "reason": "Created"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "ervice-sample-raycluster-g79cg-worker-small-group-"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 2": "in total 3"}
pod name is too long: len = 54, we will shorten it by offset = 4
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:00:44Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:44Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayservice-sample-raycluster-g79cg","uid":"95e6a72a-8af5-4c20-953d-66ef4c9b4feb","apiVersion":"ray.io/v1","resourceVersion":"241"}, "reason": "Created"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "ervice-sample-raycluster-g79cg-worker-small-group-"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	inconsistentRayClusterStatus	{"detect inconsistency": "old AvailableWorkerReplicas: 0, new AvailableWorkerReplicas: 0, old DesiredWorkerReplicas: 0, new DesiredWorkerReplicas: 3, old MinWorkerReplicas: 0, new MinWorkerReplicas: 0, old MaxWorkerReplicas: 0, new MaxWorkerReplicas: 10000"}
2023-12-08T18:00:44Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayservice-sample-raycluster-g79cg","uid":"95e6a72a-8af5-4c20-953d-66ef4c9b4feb","apiVersion":"ray.io/v1","resourceVersion":"241"}, "reason": "Created"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	rayClusterReconcile	{"Update CR status": "rayservice-sample-raycluster-g79cg", "status": {"desiredWorkerReplicas":3,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:00:44Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080","serve":"8000"},"head":{"serviceIP":"10.0.0.192"},"observedGeneration":1}}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayservice-sample-raycluster-g79cg", "seconds": 10}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayservice-sample-raycluster-g79cg-head-svc"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayservice-sample-raycluster-g79cg-head-tjjnf", "Pod status": "Running", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayservice-sample-raycluster-g79cg-head-tjjnf", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayservice-sample-raycluster-g79cg-head-tjjnf. The Pod status is Running, and the Ray container terminated status is nil."}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-g79cg-worker-small-group-8lv54", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-g79cg-worker-small-group-8lv54. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-g79cg-worker-small-group-w29zw", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-g79cg-worker-small-group-w29zw. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-g79cg-worker-small-group-vnplv", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-g79cg-worker-small-group-vnplv. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:00:44Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayservice-sample-raycluster-g79cg", "seconds": 10}
2023-12-08T18:00:44Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:44Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:44Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:00:44Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:00:44Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": true, "reason": "Nothing has been cached for cluster rayservice-sample-raycluster-g79cg with key default/rayservice-sample/rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:44Z	DEBUG	controllers.RayService	updateServeDeployment	{"V1 config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:00:44Z	DEBUG	controllers.RayService	updateServeDeployment	{"SINGLE_APP json config": "{\"import_path\":\"fruit.deployment_graph\",\"runtime_env\":{\"working_dir\":[\"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"]},\"deployments\":[{\"name\":\"MangoStand\",\"num_replicas\":1,\"user_config\":{\"price\":3},\"ray_actor_options\":{\"num_cpus\":0.1}},{\"name\":\"OrangeStand\",\"num_replicas\":1,\"user_config\":{\"price\":2},\"ray_actor_options\":{\"num_cpus\":0.1}},{\"name\":\"PearStand\",\"num_replicas\":1,\"user_config\":{\"price\":1},\"ray_actor_options\":{\"num_cpus\":0.1}}]}"}
UpdateDeployments fake succeeds.2023-12-08T18:00:44Z	DEBUG	controllers.RayService	updateServeDeployment	{"message": "Cached Serve config for Ray cluster rayservice-sample-raycluster-g79cg with key default/rayservice-sample/rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:44Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"prev statuses": null, "serve statuses": {"default":{"status":"RUNNING","deployments":{"deep":{"name":"deep","status":"HEALTHY"},"one":{"name":"one","status":"HEALTHY"},"shallow":{"name":"shallow","status":"HEALTHY"}}}}}
2023-12-08T18:00:44Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"new statuses": {"default":{"status":"RUNNING","healthLastUpdateTime":"2023-12-08T18:00:44Z","serveDeploymentStatuses":{"deep":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:00:44Z"},"one":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:00:44Z"},"shallow":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:00:44Z"}}}}}
2023-12-08T18:00:44Z	INFO	controllers.RayService	Check serve health	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "isReady": true, "isActive": false}
2023-12-08T18:00:44Z	DEBUG	controllers.RayService	updateRayClusterInfo	{"ActiveRayClusterName": "", "healthyClusterName": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:44Z	INFO	controllers.RayService	Reconciling the ingress and service resources on the pending Ray cluster.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:44Z	INFO	controllers.RayService	Ingress is disabled. Skipping ingress reconcilation. You can enable Ingress by setting enableIngress to true in HeadGroupSpec.
2023-12-08T18:00:44Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "headService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:00:44Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-head-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/identifier:rayservice-sample-head ray.io/node-type:head ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:dashboard,Protocol:,Port:8265,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:dashboard-agent,Protocol:,Port:52365,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:gcs-server,Protocol:,Port:6379,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:head,Protocol:,Port:10001,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:metrics,Protocol:,Port:8080,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},},Selector:map[string]string{app.kubernetes.io/created-by: kuberay-operator,app.kubernetes.io/name: kuberay,ray.io/cluster: rayservice-sample-raycluster-g79cg,ray.io/identifier: rayservice-sample-raycluster-g79cg-head,ray.io/node-type: head,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:00:44Z	INFO	controllers.RayService	Create a Kubernetes Service for RayService serviceType headService
2023-12-08T18:00:44Z	DEBUG	events	Controller sent API request to update Serve deployments on cluster rayservice-sample-raycluster-g79cg	{"type": "Normal", "object": {"kind":"RayService","namespace":"default","name":"rayservice-sample","uid":"4a8484cc-467c-4f14-8a8c-1aacfcfebd2a","apiVersion":"ray.io/v1","resourceVersion":"239"}, "reason": "SubmittedServeDeployment"}
2023-12-08T18:00:44Z	DEBUG	events	The Serve applicaton is now running and healthy.	{"type": "Normal", "object": {"kind":"RayService","namespace":"default","name":"rayservice-sample","uid":"4a8484cc-467c-4f14-8a8c-1aacfcfebd2a","apiVersion":"ray.io/v1","resourceVersion":"239"}, "reason": "Running"}
2023-12-08T18:00:44Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "serveService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:00:44Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-serve-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/serve:rayservice-sample-serve ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{ray.io/cluster: rayservice-sample-raycluster-g79cg,ray.io/serve: true,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:00:44Z	INFO	controllers.RayService	Create a Kubernetes Service for RayService serviceType serveService
2023-12-08T18:00:44Z	INFO	controllers.RayService	inconsistentRayServiceStatus RayService ServiceStatus changed from Restarting to Running
2023-12-08T18:00:45Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:00:45Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:45Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:00:45Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:00:45Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:00:45Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"prev statuses": {"default":{"status":"RUNNING","healthLastUpdateTime":"2023-12-08T18:00:44Z","serveDeploymentStatuses":{"deep":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:00:44Z"},"one":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:00:44Z"},"shallow":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:00:44Z"}}}}, "serve statuses": {"default":{"status":"RUNNING","deployments":{"deep":{"name":"deep","status":"HEALTHY"},"one":{"name":"one","status":"HEALTHY"},"shallow":{"name":"shallow","status":"HEALTHY"}}}}}
2023-12-08T18:00:45Z	DEBUG	controllers.RayService	getAndCheckServeStatus	{"new statuses": {"default":{"status":"RUNNING","healthLastUpdateTime":"2023-12-08T18:00:45Z","serveDeploymentStatuses":{"deep":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:00:45Z"},"one":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:00:45Z"},"shallow":{"status":"HEALTHY","healthLastUpdateTime":"2023-12-08T18:00:45Z"}}}}}
2023-12-08T18:00:45Z	INFO	controllers.RayService	Check serve health	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "isReady": true, "isActive": true}
2023-12-08T18:00:45Z	DEBUG	controllers.RayService	updateRayClusterInfo	{"ActiveRayClusterName": "rayservice-sample-raycluster-g79cg", "healthyClusterName": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:45Z	INFO	controllers.RayService	Reconciling the ingress and service resources on the active Ray cluster. No pending Ray cluster found.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayService	Ingress is disabled. Skipping ingress reconcilation. You can enable Ingress by setting enableIngress to true in HeadGroupSpec.
2023-12-08T18:00:45Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "headService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:00:45Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-head-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/identifier:rayservice-sample-head ray.io/node-type:head ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:dashboard,Protocol:,Port:8265,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:dashboard-agent,Protocol:,Port:52365,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:gcs-server,Protocol:,Port:6379,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:head,Protocol:,Port:10001,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:metrics,Protocol:,Port:8080,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:*tcp,},},Selector:map[string]string{app.kubernetes.io/created-by: kuberay-operator,app.kubernetes.io/name: kuberay,ray.io/cluster: rayservice-sample-raycluster-g79cg,ray.io/identifier: rayservice-sample-raycluster-g79cg-head,ray.io/node-type: head,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:00:45Z	INFO	controllers.RayService	RayCluster rayservice-sample-raycluster-g79cg's headService has already exists, skip Update
2023-12-08T18:00:45Z	INFO	controllers.RayService	reconcileServices	{"serviceType": "serveService", "RayService name": "rayservice-sample", "RayService namespace": "default"}
2023-12-08T18:00:45Z	INFO	controllers.RayService	reconcileServices	{"newSvc": "&Service{ObjectMeta:{rayservice-sample-serve-svc  default    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[ray.io/serve:rayservice-sample-serve ray.io/service:rayservice-sample] map[] [] [] []},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:serve,Protocol:,Port:8000,TargetPort:{0 0 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{ray.io/cluster: rayservice-sample-raycluster-g79cg,ray.io/serve: true,},ClusterIP:,Type:,ExternalIPs:[],SessionAffinity:,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:nil,ClusterIPs:[],IPFamilies:[],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:nil,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{},},Conditions:[]Condition{},},}"}
2023-12-08T18:00:45Z	INFO	controllers.RayService	RayCluster rayservice-sample-raycluster-g79cg's serveService has already exists, skip Update
2023-12-08T18:00:45Z	DEBUG	events	The Serve applicaton is now running and healthy.	{"type": "Normal", "object": {"kind":"RayService","namespace":"default","name":"rayservice-sample","uid":"4a8484cc-467c-4f14-8a8c-1aacfcfebd2a","apiVersion":"ray.io/v1","resourceVersion":"263"}, "reason": "Running"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-b4g78", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0mSetup mock first: 2023-12-08 18:00:45.476819512 +0000 UTC m=+18.245897848


2023-12-08T18:00:45Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Add a finalizer	{"finalizer": "ray.io/rayjob-finalizer"}
[38;5;10mâ€¢[0m2023-12-08T18:00:45Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": true, "RayJob": "rayjob-delayed-dashbaord", "jobId": "", "rayClusterName": "", "jobStatus": ""}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "", "newJobDeploymentStatus": "Initializing"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	RayCluster not found, creating RayCluster!	{"raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-delayed-dashbaord-raycluster-nsd2z"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:45Z	INFO	controllers.RayJob	created rayCluster for rayJob	{"rayCluster": {"metadata":{"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default","uid":"619cd20e-0ed6-46a7-accd-281441629d4c","resourceVersion":"268","generation":1,"creationTimestamp":"2023-12-08T18:00:45Z","ownerReferences":[{"apiVersion":"ray.io/v1","kind":"RayJob","name":"rayjob-delayed-dashbaord","uid":"c93158dc-2259-4721-bd7e-a19be7a9a8f9","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"ray.test","operation":"Update","apiVersion":"ray.io/v1","time":"2023-12-08T18:00:45Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"c93158dc-2259-4721-bd7e-a19be7a9a8f9\"}":{}}},"f:spec":{".":{},"f:headGroupSpec":{".":{},"f:rayStartParams":{".":{},"f:dashboard-agent-listen-port":{},"f:dashboard-host":{},"f:node-ip-address":{},"f:num-cpus":{},"f:object-store-memory":{},"f:port":{}},"f:template":{".":{},"f:metadata":{".":{},"f:annotations":{".":{},"f:key":{}},"f:labels":{".":{},"f:groupName":{}}},"f:spec":{".":{},"f:containers":{}}}},"f:rayVersion":{},"f:workerGroupSpecs":{}}}}]},"spec":{"headGroupSpec":{"rayStartParams":{"dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"},"template":{"metadata":{"creationTimestamp":null,"labels":{"groupName":"headgroup"},"annotations":{"key":"value"}},"spec":{"containers":[{"name":"ray-head","image":"rayproject/ray:2.8.0","ports":[{"name":"gcs-server","containerPort":6379,"protocol":"TCP"},{"name":"dashboard","containerPort":8265,"protocol":"TCP"},{"name":"head","containerPort":10001,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}]}}},"workerGroupSpecs":[{"groupName":"small-group","replicas":3,"minReplicas":0,"maxReplicas":10000,"rayStartParams":{"dashboard-agent-listen-port":"52365","num-cpus":"1","port":"6379"},"template":{"metadata":{"namespace":"default","creationTimestamp":null,"labels":{"groupName":"small-group"}},"spec":{"containers":[{"name":"ray-worker","image":"rayproject/ray:2.8.0","command":["echo"],"args":["Hello Ray"],"ports":[{"name":"client","containerPort":80,"protocol":"TCP"},{"name":"dashboard-agent","containerPort":52365,"protocol":"TCP"}],"env":[{"name":"MY_POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}}],"resources":{}}]}},"scaleStrategy":{}}],"rayVersion":"1.12.1"},"status":{"head":{}}}}
2023-12-08T18:00:45Z	ERROR	controllers.RayJob	Head service is not found	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default", "error": "Service \"rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc\" not found"}
github.com/ray-project/kuberay/ray-operator/controllers/ray/utils.FetchHeadServiceURL
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/utils/dashboard_httpclient.go:83
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayJobReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayjob_controller.go:191
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:45Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "Initializing", "newJobDeploymentStatus": "WaitForDashboard"}
2023-12-08T18:00:45Z	DEBUG	events	Created cluster rayjob-delayed-dashbaord-raycluster-nsd2z	{"type": "Normal", "object": {"kind":"RayJob","namespace":"default","name":"rayjob-delayed-dashbaord","uid":"c93158dc-2259-4721-bd7e-a19be7a9a8f9","apiVersion":"ray.io/v1","resourceVersion":"267"}, "reason": "Created"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	Pod Service created successfully	{"service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"Found 0 head Pods; creating a head Pod for the RayCluster.": "rayjob-delayed-dashbaord-raycluster-nsd2z"}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	Setting pod namespaces	{"namespace": "default"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	head pod labels	{"labels": {"app.kubernetes.io/created-by":"kuberay-operator","app.kubernetes.io/name":"kuberay","groupName":"headgroup","ray.io/cluster":"rayjob-delayed-dashbaord-raycluster-nsd2z","ray.io/group":"headgroup","ray.io/identifier":"rayjob-delayed-dashbaord-raycluster-nsd2z-head","ray.io/is-ray-node":"yes","ray.io/node-type":"head"}}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "head", "rayStartParams": {"block":"true","dashboard-agent-listen-port":"52365","dashboard-host":"0.0.0.0","metrics-export-port":"8080","node-ip-address":"127.0.0.1","num-cpus":"1","object-store-memory":"100000000","port":"6379"}, "Ray container resource": {"limits":{"cpu":"1","memory":"2Gi"},"requests":{"cpu":"1","memory":"2Gi"}}}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start --head  --port=6379  --dashboard-agent-listen-port=52365  --block  --memory=2147483648  --dashboard-host=0.0.0.0  --node-ip-address=127.0.0.1  --num-cpus=1  --object-store-memory=100000000  --metrics-export-port=8080 "}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "head", "generatedCmd": "ulimit -n 65536; ray start --head  --port=6379  --dashboard-agent-listen-port=52365  --block  --memory=2147483648  --dashboard-host=0.0.0.0  --node-ip-address=127.0.0.1  --num-cpus=1  --object-store-memory=100000000  --metrics-export-port=8080 "}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	createHeadPod	{"head pod with name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-"}
2023-12-08T18:00:45Z	DEBUG	events	Created service rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-delayed-dashbaord-raycluster-nsd2z","uid":"619cd20e-0ed6-46a7-accd-281441629d4c","apiVersion":"ray.io/v1","resourceVersion":"268"}, "reason": "Created"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 0, "diff": 3}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"Number workers to add": 3, "Worker group": "small-group"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 0": "in total 3"}
pod name is too long: len = 61, we will shorten it by offset = 11
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --dashboard-agent-listen-port=52365  --num-cpus=1  --port=6379  --address=rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block "}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:45Z	DEBUG	events	Created head pod rayjob-delayed-dashbaord-raycluster-nsd2z-head-fxf78	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-delayed-dashbaord-raycluster-nsd2z","uid":"619cd20e-0ed6-46a7-accd-281441629d4c","apiVersion":"ray.io/v1","resourceVersion":"268"}, "reason": "Created"}
2023-12-08T18:00:45Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-delayed-dashbaord","namespace":"default"}, "namespace": "default", "name": "rayjob-delayed-dashbaord", "reconcileID": "3cc31d6a-869d-4828-b75c-3a5bd36d62f5"}
2023-12-08T18:00:45Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-delayed-dashbaord","namespace":"default"}, "namespace": "default", "name": "rayjob-delayed-dashbaord", "reconcileID": "3cc31d6a-869d-4828-b75c-3a5bd36d62f5", "error": "Service \"rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc\" not found"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:45Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-8ddzj", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-nsd2z", "jobStatus": "PENDING"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboard", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "yed-dashbaord-raycluster-nsd2z-worker-small-group-"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 1": "in total 3"}
2023-12-08T18:00:45Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-delayed-dashbaord-raycluster-nsd2z","uid":"619cd20e-0ed6-46a7-accd-281441629d4c","apiVersion":"ray.io/v1","resourceVersion":"268"}, "reason": "Created"}
pod name is too long: len = 61, we will shorten it by offset = 11
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --port=6379  --address=rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --dashboard-agent-listen-port=52365  --num-cpus=1 "}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --port=6379  --address=rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --dashboard-agent-listen-port=52365  --num-cpus=1 "}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:45Z	INFO	Warning: Reconciler returned both a non-zero result and a non-nil error. The result will always be ignored if the error is non-nil and the non-nil error causes reqeueuing with exponential backoff. For more details, see: https://pkg.go.dev/sigs.k8s.io/controller-runtime/pkg/reconcile#Reconciler	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-delayed-dashbaord","namespace":"default"}, "namespace": "default", "name": "rayjob-delayed-dashbaord", "reconcileID": "0c9283be-4c62-4be3-a806-44258d3191db"}
2023-12-08T18:00:45Z	ERROR	Reconciler error	{"controller": "rayjob", "controllerGroup": "ray.io", "controllerKind": "RayJob", "RayJob": {"name":"rayjob-delayed-dashbaord","namespace":"default"}, "namespace": "default", "name": "rayjob-delayed-dashbaord", "reconcileID": "0c9283be-4c62-4be3-a806-44258d3191db", "error": "dashboard is not ready"}
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:329
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:45Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-8ddzj", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-nsd2z", "jobStatus": "PENDING"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "yed-dashbaord-raycluster-nsd2z-worker-small-group-"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"creating worker for group": "small-group", "index 2": "in total 3"}
pod name is too long: len = 61, we will shorten it by offset = 11
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	generateRayStartCommand	{"nodeType": "worker", "rayStartParams": {"address":"rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:6379","block":"true","dashboard-agent-listen-port":"52365","metrics-export-port":"8080","num-cpus":"1","port":"6379"}, "Ray container resource": {}}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	generateRayStartCommand	{"rayStartCmd": "ray start  --port=6379  --address=rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --dashboard-agent-listen-port=52365  --num-cpus=1 "}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	BuildPod	{"rayNodeType": "worker", "generatedCmd": "ulimit -n 65536; ray start  --port=6379  --address=rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:6379  --metrics-export-port=8080  --block  --dashboard-agent-listen-port=52365  --num-cpus=1 "}
2023-12-08T18:00:45Z	INFO	RayCluster-Controller	Probes injection feature flag	{"enabled": true}
2023-12-08T18:00:45Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-delayed-dashbaord-raycluster-nsd2z","uid":"619cd20e-0ed6-46a7-accd-281441629d4c","apiVersion":"ray.io/v1","resourceVersion":"268"}, "reason": "Created"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	Created pod	{"Pod ": "yed-dashbaord-raycluster-nsd2z-worker-small-group-"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	inconsistentRayClusterStatus	{"detect inconsistency": "old AvailableWorkerReplicas: 0, new AvailableWorkerReplicas: 0, old DesiredWorkerReplicas: 0, new DesiredWorkerReplicas: 3, old MinWorkerReplicas: 0, new MinWorkerReplicas: 0, old MaxWorkerReplicas: 0, new MaxWorkerReplicas: 10000"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	rayClusterReconcile	{"Update CR status": "rayjob-delayed-dashbaord-raycluster-nsd2z", "status": {"desiredWorkerReplicas":3,"maxWorkerReplicas":10000,"lastUpdateTime":"2023-12-08T18:00:45Z","endpoints":{"dashboard":"8265","dashboard-agent":"52365","gcs-server":"6379","head":"10001","metrics":"8080"},"head":{"serviceIP":"10.0.0.78"},"observedGeneration":1}}
2023-12-08T18:00:45Z	DEBUG	events	Created worker pod 	{"type": "Normal", "object": {"kind":"RayCluster","namespace":"default","name":"rayjob-delayed-dashbaord-raycluster-nsd2z","uid":"619cd20e-0ed6-46a7-accd-281441629d4c","apiVersion":"ray.io/v1","resourceVersion":"268"}, "reason": "Created"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-8ddzj", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-nsd2z", "jobStatus": "PENDING"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-8ddzj", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-nsd2z", "jobStatus": "PENDING"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "err": "dashboard is not ready"}
2023-12-08T18:00:45Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-delayed-dashbaord-raycluster-nsd2z", "seconds": 10}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-delayed-dashbaord-raycluster-nsd2z"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-fxf78", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-fxf78", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-delayed-dashbaord-raycluster-nsd2z-head-fxf78. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-nsd2z-worker-small-group-b4x8z", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-nsd2z-worker-small-group-b4x8z. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-nsd2z-worker-small-group-mxl74", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-nsd2z-worker-small-group-mxl74. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-nsd2z-worker-small-group-rlbhs", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-nsd2z-worker-small-group-rlbhs. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:00:45Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-delayed-dashbaord-raycluster-nsd2z", "seconds": 10}
[38;5;10mâ€¢[0m2023-12-08T18:00:46Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:46Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:00:46Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:46Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:46Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:00:46Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:00:46Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:00:46Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:47Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:47Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:47Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:47Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:47Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-b4g78", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-8ddzj", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-nsd2z", "jobStatus": "PENDING"}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default"}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-8ddzj\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:00:48Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:00:48Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:48Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:00:48Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:48Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:48Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:00:48Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:00:48Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:00:48Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:50Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:50Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:50Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:50Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:50Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:50Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:50Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:00:50Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:50Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:50Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:00:50Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:00:50Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:00:50Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:51Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-b4g78", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-8ddzj", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-nsd2z", "jobStatus": "PENDING"}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default"}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-8ddzj\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:00:51Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-kvjgm-head-svc"}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-kvjgm-head-69rll. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 4, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 4}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-sr27m", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-sr27m. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-kqxw4", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-kqxw4. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-hm8q6", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-hm8q6. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-l74qb", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-l74qb. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 4, "runningPods": 4, "diff": 0}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:00:51Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-kvjgm", "seconds": 10}
2023-12-08T18:00:52Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:52Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:00:52Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:52Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:52Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:00:52Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:00:52Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:00:52Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:53Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:53Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:53Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:53Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:53Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-b4g78", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-8ddzj", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-nsd2z", "jobStatus": "PENDING"}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default"}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-8ddzj\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:00:54Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:00:54Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:54Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:00:54Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:54Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:54Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:00:54Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:00:54Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:00:54Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayservice-sample-raycluster-g79cg-head-svc"}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayservice-sample-raycluster-g79cg-head-tjjnf", "Pod status": "Running", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayservice-sample-raycluster-g79cg-head-tjjnf", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayservice-sample-raycluster-g79cg-head-tjjnf. The Pod status is Running, and the Ray container terminated status is nil."}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-g79cg-worker-small-group-8lv54", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-g79cg-worker-small-group-8lv54. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-g79cg-worker-small-group-w29zw", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-g79cg-worker-small-group-w29zw. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-g79cg-worker-small-group-vnplv", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-g79cg-worker-small-group-vnplv. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:00:54Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayservice-sample-raycluster-g79cg", "seconds": 10}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-delayed-dashbaord-raycluster-nsd2z"}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc"}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-fxf78", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-fxf78", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-delayed-dashbaord-raycluster-nsd2z-head-fxf78. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-nsd2z-worker-small-group-mxl74", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-nsd2z-worker-small-group-mxl74. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-nsd2z-worker-small-group-rlbhs", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-nsd2z-worker-small-group-rlbhs. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-nsd2z-worker-small-group-b4x8z", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-nsd2z-worker-small-group-b4x8z. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:00:55Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-delayed-dashbaord-raycluster-nsd2z", "seconds": 10}
2023-12-08T18:00:56Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:56Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:56Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:56Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:56Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:56Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:56Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:00:56Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:56Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:56Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:00:56Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:00:56Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:00:56Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:57Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-b4g78", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-8ddzj", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-nsd2z", "jobStatus": "PENDING"}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default"}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-8ddzj\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:00:57Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:00:58Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:58Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:00:58Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:00:58Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:00:58Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:00:58Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:00:58Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:00:58Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:00:59Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:00:59Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:00:59Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:00:59Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:00:59Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-b4g78", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-8ddzj", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-nsd2z", "jobStatus": "PENDING"}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default"}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-8ddzj\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:01:00Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:01:00Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:01:00Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:01:00Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:01:00Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:01:00Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:01:00Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:01:00Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:01:00Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-test-default-raycluster-kvjgm-head-svc"}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-test-default-raycluster-kvjgm-head-69rll", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-test-default-raycluster-kvjgm-head-69rll. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 4, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 4}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-kqxw4", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-kqxw4. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-hm8q6", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-hm8q6. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-l74qb", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-l74qb. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "rtest-default-raycluster-kvjgm-worker-small-group-sr27m", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod rtest-default-raycluster-kvjgm-worker-small-group-sr27m. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 4, "runningPods": 4, "diff": 0}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:01:01Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-test-default-raycluster-kvjgm", "seconds": 10}
2023-12-08T18:01:02Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:01:02Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:01:02Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:01:02Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:01:02Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:01:02Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:01:02Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:01:02Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:01:02Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:01:02Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:01:02Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:01:02Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:01:02Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:01:03Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default-2","namespace":"default"}}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default-2", "jobId": "rayjob-test-default-2-b4g78", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default-2", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	ClusterSelector is being used to select an existing RayCluster. RayClusterSpec will be disregarded	{"raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-delayed-dashbaord","namespace":"default"}}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-delayed-dashbaord", "jobId": "rayjob-delayed-dashbaord-8ddzj", "rayClusterName": "rayjob-delayed-dashbaord-raycluster-nsd2z", "jobStatus": "PENDING"}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-delayed-dashbaord", "raycluster": {"name":"rayjob-delayed-dashbaord-raycluster-nsd2z","namespace":"default"}}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service name": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc", "namespace": "default"}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	FetchHeadServiceURL	{"head service URL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "port": "dashboard"}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	Fail to GetJobInfo	{"DashboardURL": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265", "err": "Get \"http://rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local:8265/api/jobs/rayjob-delayed-dashbaord-8ddzj\": dial tcp: lookup rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc.default.svc.cluster.local: Temporary failure in name resolution"}
2023-12-08T18:01:03Z	INFO	controllers.RayJob	UpdateState	{"oldJobStatus": "PENDING", "newJobStatus": "PENDING", "oldJobDeploymentStatus": "WaitForDashboardReady", "newJobDeploymentStatus": "WaitForDashboardReady"}
2023-12-08T18:01:04Z	INFO	controllers.RayService	Reconciling the cluster component.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:01:04Z	INFO	controllers.RayService	Active Ray cluster config matches goal config.
2023-12-08T18:01:04Z	INFO	controllers.RayService	Reconciling the Serve component. Only the active Ray cluster exists.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}}
2023-12-08T18:01:04Z	INFO	controllers.RayService	Check the head Pod status of the pending RayCluster	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "RayCluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:01:04Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service name": "rayservice-sample-raycluster-g79cg-head-svc", "namespace": "default"}
2023-12-08T18:01:04Z	INFO	controllers.RayService	FetchHeadServiceURL	{"head service URL": "rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365", "port": "dashboard-agent"}
2023-12-08T18:01:04Z	DEBUG	controllers.RayService	shouldUpdate	{"shouldUpdateServe": false, "reason": "Current Serve config matches cached Serve config, and some deployments have been deployed for cluster rayservice-sample-raycluster-g79cg", "cachedServeConfig": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}, "current Serve config": {"importPath":"fruit.deployment_graph","runtimeEnv":"working_dir:\n - \"https://github.com/ray-project/test_dag/archive/c620251044717ace0a4c19d766d43c5099af8a77.zip\"","deployments":[{"name":"MangoStand","numReplicas":1,"userConfig":"price: 3","rayActorOptions":{"numCpus":0.1}},{"name":"OrangeStand","numReplicas":1,"userConfig":"price: 2","rayActorOptions":{"numCpus":0.1}},{"name":"PearStand","numReplicas":1,"userConfig":"price: 1","rayActorOptions":{"numCpus":0.1}}]}}
2023-12-08T18:01:04Z	ERROR	controllers.RayService	Fail to reconcileServe.	{"ServiceName": {"name":"rayservice-sample","namespace":"default"}, "error": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused", "errorVerbose": "combined error: Failed to get Serve deployment statuses from the head's dashboard agent port (the head service's port with the name `dashboard-agent`). If you observe this error consistently, please check https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayservice-troubleshooting.md for more details. err: Get \"http://rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local:52365/api/serve/deployments/status\": dial tcp: lookup rayservice-sample-raycluster-g79cg-head-svc.default.svc.cluster.local: Temporary failure in name resolution Put \"https://127.0.0.1:33517/apis/ray.io/v1/namespaces/default/rayservices/rayservice-sample/status\": dial tcp 127.0.0.1:33517: connect: connection refused\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).updateState\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:334\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).reconcileServe\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:1070\ngithub.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile\n\t/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:146\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\n\t/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227\nruntime.goexit\n\t/home/ubuntu/sdk/go1.21.3/src/runtime/asm_amd64.s:1650"}
github.com/ray-project/kuberay/ray-operator/controllers/ray.(*RayServiceReconciler).Reconcile
	/home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/rayservice_controller.go:147
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:119
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:316
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:266
sigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2
	/home/ubuntu/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.16.3/pkg/internal/controller/controller.go:227
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayservice-sample-raycluster-g79cg"}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayservice-sample-raycluster-g79cg-head-svc"}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayservice-sample-raycluster-g79cg-head-tjjnf", "Pod status": "Running", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayservice-sample-raycluster-g79cg-head-tjjnf", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayservice-sample-raycluster-g79cg-head-tjjnf. The Pod status is Running, and the Ray container terminated status is nil."}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-g79cg-worker-small-group-vnplv", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-g79cg-worker-small-group-vnplv. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-g79cg-worker-small-group-8lv54", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-g79cg-worker-small-group-8lv54. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "ervice-sample-raycluster-g79cg-worker-small-group-w29zw", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod ervice-sample-raycluster-g79cg-worker-small-group-w29zw. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:01:04Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayservice-sample-raycluster-g79cg", "seconds": 10}
2023-12-08T18:01:05Z	INFO	controllers.RayJob	reconciling RayJob	{"NamespacedName": {"name":"rayjob-test-default","namespace":"default"}}
2023-12-08T18:01:05Z	INFO	controllers.RayJob	initRayJobStatusIfNeed	{"shouldUpdateStatus": false, "RayJob": "rayjob-test-default", "jobId": "rayjob-test-default-brfsq", "rayClusterName": "rayjob-test-default-raycluster-kvjgm", "jobStatus": "PENDING"}
2023-12-08T18:01:05Z	INFO	controllers.RayJob	Found associated RayCluster for RayJob	{"rayjob": "rayjob-test-default", "raycluster": {"name":"rayjob-test-default-raycluster-kvjgm","namespace":"default"}}
2023-12-08T18:01:05Z	INFO	controllers.RayJob	Ray dashboard is ready	{"DashboardURL": "rayjob-test-default-raycluster-kvjgm-head-svc.default.svc.cluster.local:8265"}
2023-12-08T18:01:05Z	INFO	controllers.RayJob	waiting for the cluster to be ready	{"rayCluster": "rayjob-test-default-raycluster-kvjgm"}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconciling RayCluster	{"cluster name": "rayjob-delayed-dashbaord-raycluster-nsd2z"}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	Reconciling Ingress
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconcileHeadService	{"1 head service found": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-svc"}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconcilePods	{"Found 1 head Pod": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-fxf78", "Pod status": "Pending", "Pod restart policy": "Always", "Ray container terminated status": "nil"}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconcilePods	{"head Pod": "rayjob-delayed-dashbaord-raycluster-nsd2z-head-fxf78", "shouldDelete": false, "reason": "KubeRay does not need to delete the head Pod rayjob-delayed-dashbaord-raycluster-nsd2z-head-fxf78. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconcilePods	{"desired workerReplicas (always adhering to minReplicas/maxReplica)": 3, "worker group": "small-group", "maxReplicas": 10000, "minReplicas": 0, "replicas": 3}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-nsd2z-worker-small-group-b4x8z", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-nsd2z-worker-small-group-b4x8z. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-nsd2z-worker-small-group-mxl74", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-nsd2z-worker-small-group-mxl74. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconcilePods	{"worker Pod": "yed-dashbaord-raycluster-nsd2z-worker-small-group-rlbhs", "shouldDelete": false, "reason": "KubeRay does not need to delete the worker Pod yed-dashbaord-raycluster-nsd2z-worker-small-group-rlbhs. The Pod status is Pending, and the Ray container terminated status is nil."}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconcilePods	{"removing the pods in the scaleStrategy of": "small-group"}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconcilePods	{"workerReplicas": 3, "runningPods": 3, "diff": 0}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	reconcilePods	{"all workers already exist for group": "small-group"}
2023-12-08T18:01:05Z	INFO	controllers.RayCluster	Unconditional requeue after	{"cluster name": "rayjob-delayed-dashbaord-raycluster-nsd2z", "seconds": 10}


[38;5;10m[1mRan 13 of 13 Specs in 38.755 seconds[0m
[38;5;10m[1mSUCCESS![0m -- [38;5;10m[1m13 Passed[0m | [38;5;9m[1m0 Failed[0m | [38;5;11m[1m0 Pending[0m | [38;5;14m[1m0 Skipped[0m
--- PASS: TestAPIs (38.76s)
PASS
coverage: 43.2% of statements
ok  	github.com/ray-project/kuberay/ray-operator/controllers/ray	38.835s	coverage: 43.2% of statements
=== RUN   TestCreatePodGroup
--- PASS: TestCreatePodGroup (0.00s)
PASS
coverage: 9.1% of statements
ok  	github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler/volcano	0.112s	coverage: 9.1% of statements
=== RUN   TestBuildIngressForHeadServiceWithoutIngressClass
time="2023-12-08T18:00:27Z" level=warning msg="ingress class annotation is not set for cluster default/raycluster-sample"
--- PASS: TestBuildIngressForHeadServiceWithoutIngressClass (0.00s)
=== RUN   TestBuildIngressForHeadService
--- PASS: TestBuildIngressForHeadService (0.00s)
=== RUN   TestGetDecodedRuntimeEnv
--- PASS: TestGetDecodedRuntimeEnv (0.00s)
=== RUN   TestGetRuntimeEnvJsonFromBase64
--- PASS: TestGetRuntimeEnvJsonFromBase64 (0.00s)
=== RUN   TestGetRuntimeEnvJsonFromYAML
--- PASS: TestGetRuntimeEnvJsonFromYAML (0.00s)
=== RUN   TestGetRuntimeEnvJsonErrorWithBothFields
--- PASS: TestGetRuntimeEnvJsonErrorWithBothFields (0.00s)
=== RUN   TestGetBaseRayJobCommand
--- PASS: TestGetBaseRayJobCommand (0.00s)
=== RUN   TestGetMetadataJson
--- PASS: TestGetMetadataJson (0.00s)
=== RUN   TestGetK8sJobCommand
--- PASS: TestGetK8sJobCommand (0.00s)
=== RUN   TestGetK8sJobCommandWithYAML
--- PASS: TestGetK8sJobCommandWithYAML (0.00s)
=== RUN   TestMetadataRaisesErrorBeforeRay26
--- PASS: TestMetadataRaisesErrorBeforeRay26 (0.00s)
=== RUN   TestGetDefaultSubmitterTemplate
--- PASS: TestGetDefaultSubmitterTemplate (0.00s)
=== RUN   TestAddEmptyDirVolumes
--- PASS: TestAddEmptyDirVolumes (0.00s)
=== RUN   TestGetHeadPort
--- PASS: TestGetHeadPort (0.00s)
=== RUN   TestBuildPod
--- PASS: TestBuildPod (0.00s)
=== RUN   TestBuildPod_WithOverwriteCommand
--- PASS: TestBuildPod_WithOverwriteCommand (0.00s)
=== RUN   TestBuildPod_WithAutoscalerEnabled
--- PASS: TestBuildPod_WithAutoscalerEnabled (0.00s)
=== RUN   TestBuildPod_WithCreatedByRayService
--- PASS: TestBuildPod_WithCreatedByRayService (0.00s)
=== RUN   TestBuildPod_WithGcsFtEnabled
--- PASS: TestBuildPod_WithGcsFtEnabled (0.00s)
=== RUN   TestBuildPodWithAutoscalerOptions
--- PASS: TestBuildPodWithAutoscalerOptions (0.00s)
=== RUN   TestHeadPodTemplate_WithAutoscalingEnabled
label value is too long: len = 205, we will shorten it by offset = 142
pod name is too long: len = 200, we will shorten it by offset = 150
pod name is too long: len = 200, we will shorten it by offset = 150
--- PASS: TestHeadPodTemplate_WithAutoscalingEnabled (0.00s)
=== RUN   TestHeadPodTemplate_AutoscalerImage
--- PASS: TestHeadPodTemplate_AutoscalerImage (0.00s)
=== RUN   TestHeadPodTemplate_WithNoServiceAccount
--- PASS: TestHeadPodTemplate_WithNoServiceAccount (0.00s)
=== RUN   TestHeadPodTemplate_WithServiceAccountNoAutoscaling
--- PASS: TestHeadPodTemplate_WithServiceAccountNoAutoscaling (0.00s)
=== RUN   TestHeadPodTemplate_WithServiceAccount
--- PASS: TestHeadPodTemplate_WithServiceAccount (0.00s)
=== RUN   TestValidateHeadRayStartParams_OK
--- PASS: TestValidateHeadRayStartParams_OK (0.00s)
=== RUN   TestValidateHeadRayStartParams_ValidWithObjectStoreMemoryError
--- PASS: TestValidateHeadRayStartParams_ValidWithObjectStoreMemoryError (0.00s)
=== RUN   TestValidateHeadRayStartParams_InvalidObjectStoreMemory
--- PASS: TestValidateHeadRayStartParams_InvalidObjectStoreMemory (0.00s)
=== RUN   TestCleanupInvalidVolumeMounts
--- PASS: TestCleanupInvalidVolumeMounts (0.00s)
=== RUN   TestDefaultWorkerPodTemplateWithName
--- PASS: TestDefaultWorkerPodTemplateWithName (0.00s)
=== RUN   TestDefaultHeadPodTemplateWithConfigurablePorts
--- PASS: TestDefaultHeadPodTemplateWithConfigurablePorts (0.00s)
=== RUN   TestDefaultWorkerPodTemplateWithConfigurablePorts
--- PASS: TestDefaultWorkerPodTemplateWithConfigurablePorts (0.00s)
=== RUN   TestDefaultInitContainer
--- PASS: TestDefaultInitContainer (0.00s)
=== RUN   TestDefaultInitContainerImagePullPolicy
=== RUN   TestDefaultInitContainerImagePullPolicy/Always
=== RUN   TestDefaultInitContainerImagePullPolicy/IfNotPresent
=== RUN   TestDefaultInitContainerImagePullPolicy/Never
--- PASS: TestDefaultInitContainerImagePullPolicy (0.00s)
    --- PASS: TestDefaultInitContainerImagePullPolicy/Always (0.00s)
    --- PASS: TestDefaultInitContainerImagePullPolicy/IfNotPresent (0.00s)
    --- PASS: TestDefaultInitContainerImagePullPolicy/Never (0.00s)
=== RUN   TestSetMissingRayStartParamsAddress
--- PASS: TestSetMissingRayStartParamsAddress (0.00s)
=== RUN   TestSetMissingRayStartParamsMetricsExportPort
--- PASS: TestSetMissingRayStartParamsMetricsExportPort (0.00s)
=== RUN   TestSetMissingRayStartParamsBlock
--- PASS: TestSetMissingRayStartParamsBlock (0.00s)
=== RUN   TestSetMissingRayStartParamsDashboardHost
--- PASS: TestSetMissingRayStartParamsDashboardHost (0.00s)
=== RUN   TestSetMissingRayStartParamsAgentListenPort
--- PASS: TestSetMissingRayStartParamsAgentListenPort (0.00s)
=== RUN   TestGetCustomWorkerInitImage
--- PASS: TestGetCustomWorkerInitImage (0.00s)
=== RUN   TestGetEnableProbesInjection
--- PASS: TestGetEnableProbesInjection (0.00s)
=== RUN   TestInitHealthProbe
--- PASS: TestInitHealthProbe (0.00s)
=== RUN   TestBuildRoleBindingSubjectAndRoleRefName
pod name is too long: len = 200, we will shorten it by offset = 150
pod name is too long: len = 200, we will shorten it by offset = 150
=== RUN   TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_with_head_group_service_account
=== RUN   TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_without_head_group_service_account
=== RUN   TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_with_a_long_name_and_without_head_group_service_account
pod name is too long: len = 200, we will shorten it by offset = 150
pod name is too long: len = 200, we will shorten it by offset = 150
--- PASS: TestBuildRoleBindingSubjectAndRoleRefName (0.00s)
    --- PASS: TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_with_head_group_service_account (0.00s)
    --- PASS: TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_without_head_group_service_account (0.00s)
    --- PASS: TestBuildRoleBindingSubjectAndRoleRefName/Ray_cluster_with_a_long_name_and_without_head_group_service_account (0.00s)
=== RUN   TestBuildRouteForHeadService
--- PASS: TestBuildRouteForHeadService (0.00s)
=== RUN   TestBuildServiceForHeadPod
--- PASS: TestBuildServiceForHeadPod (0.00s)
=== RUN   TestBuildServiceForHeadPodWithAppNameLabel
--- PASS: TestBuildServiceForHeadPodWithAppNameLabel (0.00s)
=== RUN   TestBuildServiceForHeadPodWithAnnotations
--- PASS: TestBuildServiceForHeadPodWithAnnotations (0.00s)
=== RUN   TestGetPortsFromCluster
--- PASS: TestGetPortsFromCluster (0.00s)
=== RUN   TestGetServicePortsWithMetricsPort
--- PASS: TestGetServicePortsWithMetricsPort (0.00s)
=== RUN   TestUserSpecifiedHeadService
default label: key=app.kubernetes.io/name, value=kuberay
default label: key=app.kubernetes.io/created-by, value=kuberay-operator
default label: key=ray.io/cluster, value=raycluster-sample
default label: key=ray.io/identifier, value=raycluster-sample-head
default label: key=ray.io/node-type, value=head
    service_test.go:374: head service: {
          "metadata": {
            "name": "user-custom-name",
            "namespace": "default",
            "creationTimestamp": null,
            "labels": {
              "app.kubernetes.io/created-by": "kuberay-operator",
              "app.kubernetes.io/name": "kuberay",
              "ray.io/cluster": "userTemplateClusterName",
              "ray.io/identifier": "raycluster-sample-head",
              "ray.io/node-type": "head",
              "userLabelKey": "userLabelValue"
            },
            "annotations": {
              "HeadServiceAnnotationKey1": "HeadServiceAnnotationValue1",
              "HeadServiceAnnotationKey2": "HeadServiceAnnotationValue2",
              "userAnnotationKey": "userAnnotationValue"
            }
          },
          "spec": {
            "ports": [
              {
                "name": "userPort",
                "port": 12345,
                "targetPort": 0
              },
              {
                "name": "client",
                "port": 98765,
                "targetPort": 0
              },
              {
                "name": "8265-port",
                "appProtocol": "tcp",
                "port": 8265,
                "targetPort": 0
              },
              {
                "name": "serve",
                "appProtocol": "tcp",
                "port": 8000,
                "targetPort": 0
              },
              {
                "name": "metrics",
                "appProtocol": "tcp",
                "port": 8080,
                "targetPort": 0
              },
              {
                "name": "gcs",
                "appProtocol": "tcp",
                "port": 6379,
                "targetPort": 0
              }
            ],
            "selector": {
              "app.kubernetes.io/created-by": "kuberay-operator",
              "app.kubernetes.io/name": "kuberay",
              "ray.io/cluster": "userTemplateClusterName",
              "ray.io/identifier": "raycluster-sample-head",
              "ray.io/node-type": "head"
            },
            "type": "LoadBalancer"
          },
          "status": {
            "loadBalancer": {}
          }
        }
--- PASS: TestUserSpecifiedHeadService (0.00s)
=== RUN   TestNilMapDoesntErrorInUserSpecifiedHeadService
--- PASS: TestNilMapDoesntErrorInUserSpecifiedHeadService (0.00s)
=== RUN   TestBuildServiceForHeadPodPortsOrder
--- PASS: TestBuildServiceForHeadPodPortsOrder (0.00s)
=== RUN   TestBuildServeServiceForRayService
--- PASS: TestBuildServeServiceForRayService (0.00s)
=== RUN   TestBuildServeServiceForRayCluster
--- PASS: TestBuildServeServiceForRayCluster (0.00s)
=== RUN   TestBuildServeServiceForRayService_WithoutServePort
--- PASS: TestBuildServeServiceForRayService_WithoutServePort (0.00s)
=== RUN   TestUserSpecifiedServeService
--- PASS: TestUserSpecifiedServeService (0.00s)
PASS
coverage: 85.7% of statements
ok  	github.com/ray-project/kuberay/ray-operator/controllers/ray/common	0.081s	coverage: 85.7% of statements
=== RUN   TestGetClusterDomainName
=== RUN   TestGetClusterDomainName/all_good_from_env
=== RUN   TestGetClusterDomainName/No_env_set
--- PASS: TestGetClusterDomainName (0.00s)
    --- PASS: TestGetClusterDomainName/all_good_from_env (0.00s)
    --- PASS: TestGetClusterDomainName/No_env_set (0.00s)
=== RUN   TestBefore
--- PASS: TestBefore (0.00s)
=== RUN   TestStatus
--- PASS: TestStatus (0.00s)
=== RUN   TestCheckAllPodsRunning
--- PASS: TestCheckAllPodsRunning (0.00s)
=== RUN   TestCheckName
pod name is too long: len = 69, we will shorten it by offset = 19
-ca41-e903-fc3ae634b18e-lazer090scholar-director-s
pod name is too long: len = 59, we will shorten it by offset = 9
--- PASS: TestCheckName (0.00s)
=== RUN   TestGetHeadGroupServiceAccountName
=== RUN   TestGetHeadGroupServiceAccountName/Ray_cluster_with_head_group_service_account
=== RUN   TestGetHeadGroupServiceAccountName/Ray_cluster_without_head_group_service_account
--- PASS: TestGetHeadGroupServiceAccountName (0.00s)
    --- PASS: TestGetHeadGroupServiceAccountName/Ray_cluster_with_head_group_service_account (0.00s)
    --- PASS: TestGetHeadGroupServiceAccountName/Ray_cluster_without_head_group_service_account (0.00s)
=== RUN   TestReconcile_CheckNeedRemoveOldPod
--- PASS: TestReconcile_CheckNeedRemoveOldPod (0.00s)
=== RUN   TestCalculateAvailableReplicas
--- PASS: TestCalculateAvailableReplicas (0.00s)
=== RUN   TestFindContainerPort
--- PASS: TestFindContainerPort (0.00s)
=== RUN   TestGenerateHeadServiceName
--- PASS: TestGenerateHeadServiceName (0.00s)
=== RUN   TestGetWorkerGroupDesiredReplicas
time="2023-12-08T18:00:27Z" level=warning msg="minReplicas (5) is greater than maxReplicas (1), using maxReplicas as desired replicas. Please fix this to avoid any unexpected behaviors."
--- PASS: TestGetWorkerGroupDesiredReplicas (0.00s)
=== RUN   TestCalculateDesiredReplicas
=== RUN   TestCalculateDesiredReplicas/Both_groups'_Replicas_are_nil
=== RUN   TestCalculateDesiredReplicas/Group1's_Replicas_is_smaller_than_MinReplicas,_and_Group2's_Replicas_is_more_than_MaxReplicas.
=== RUN   TestCalculateDesiredReplicas/Group1's_Replicas_is_more_than_MaxReplicas.
--- PASS: TestCalculateDesiredReplicas (0.00s)
    --- PASS: TestCalculateDesiredReplicas/Both_groups'_Replicas_are_nil (0.00s)
    --- PASS: TestCalculateDesiredReplicas/Group1's_Replicas_is_smaller_than_MinReplicas,_and_Group2's_Replicas_is_more_than_MaxReplicas. (0.00s)
    --- PASS: TestCalculateDesiredReplicas/Group1's_Replicas_is_more_than_MaxReplicas. (0.00s)
=== RUN   TestUtils
Running Suite: Utils Suite - /home/ubuntu/go/src/kuberay/ray-operator/controllers/ray/utils
===========================================================================================
Random Seed: [1m1702058427[0m

Will run [1m4[0m of [1m4[0m specs
[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m[38;5;10mâ€¢[0m

[38;5;10m[1mRan 4 of 4 Specs in 0.001 seconds[0m
[38;5;10m[1mSUCCESS![0m -- [38;5;10m[1m4 Passed[0m | [38;5;9m[1m0 Failed[0m | [38;5;11m[1m0 Pending[0m | [38;5;14m[1m0 Skipped[0m
--- PASS: TestUtils (0.00s)
PASS
coverage: 29.3% of statements
ok  	github.com/ray-project/kuberay/ray-operator/controllers/ray/utils	0.056s	coverage: 29.3% of statements
# KUBEBUILDER_ASSETS="/home/ubuntu/go/src/kuberay/ray-operator/bin/k8s/1.24.2-linux-amd64" go test github.com/ray-project/kuberay/ray-operator github.com/ray-project/kuberay/ray-operator/apis/ray/v1 github.com/ray-project/kuberay/ray-operator/apis/ray/v1alpha1 github.com/ray-project/kuberay/ray-operator/controllers/ray github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler/interface github.com/ray-project/kuberay/ray-operator/controllers/ray/batchscheduler/volcano github.com/ray-project/kuberay/ray-operator/controllers/ray/common github.com/ray-project/kuberay/ray-operator/controllers/ray/utils github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/fake github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/scheme github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/typed/ray/v1 github.com/ray-project/kuberay/ray-operator/pkg/client/clientset/versioned/typed/ray/v1/fake github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/internalinterfaces github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/ray github.com/ray-project/kuberay/ray-operator/pkg/client/informers/externalversions/ray/v1 github.com/ray-project/kuberay/ray-operator/pkg/client/listers/ray/v1 -coverprofile cover.out -test.v
